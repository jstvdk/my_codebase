{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import keras_cv\n",
    "from keras_cv import bounding_box\n",
    "from keras_cv import visualization\n",
    "\n",
    "SPLIT_RATIO = 0.1\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.024\n",
    "GLOBAL_CLIPNORM = 10.0\n",
    "\n",
    "dataset_dir = \"/Users/vdk/Software/my_code/python/sofi/data/rad_photo_custom/yolo_labeled_files\"\n",
    "model_store_dir = \"/Users/vdk/Software/my_code/python/sofi/data/output\"\n",
    "\n",
    "class_ids = [\n",
    "    \"With_Radiation_sign\",\n",
    "    \"Without_Radiation_sign\",\n",
    "    \"Radiation_sign\"\n",
    "]\n",
    "\n",
    "class_mapping = dict(zip(range(len(class_ids)), class_ids))\n",
    "name2classID = {value:key for key,value in class_mapping.items()}\n",
    "\n",
    "txt_files = []\n",
    "\n",
    "for r, _, f in os.walk(dataset_dir):\n",
    "    for txt_filename in f:\n",
    "        txt_files.append(os.path.join(r, txt_filename))\n",
    "txt_files = sorted(txt_files)\n",
    "random.seed(10)\n",
    "random.shuffle(txt_files)\n",
    "\n",
    "def parse_annotation(txt_file):\n",
    "\n",
    "    image_path = txt_file.split(\"/\")\n",
    "    image_path[-2] = \"imgs\"\n",
    "    image_path[-1] = image_path[-1][:-4] + \".jpg\"\n",
    "    image_path = \"/\".join(image_path)\n",
    "\n",
    "    boxes = []\n",
    "    class_ids = []\n",
    "    with open(txt_file) as file:\n",
    "\n",
    "        try:\n",
    "            for line in file:\n",
    "                lineSplit = line.split()\n",
    "                box = lineSplit[1:]\n",
    "                box = [640*float(coor) for coor in box]\n",
    "                # correct from center to edge of the box\n",
    "                box[0] -= box[2]/2\n",
    "                box[1] -= box[3]/2\n",
    "\n",
    "                boxes.append(box)\n",
    "\n",
    "\n",
    "                class_ids.append(int(lineSplit[0]))\n",
    "        except:\n",
    "            print(f\"Filename has something wrong {txt_file}\")\n",
    "\n",
    "    return image_path, boxes, class_ids\n",
    "\n",
    "\n",
    "image_paths = []\n",
    "bbox = []\n",
    "classes = []\n",
    "for txt_file in tqdm(txt_files):\n",
    "    image_path, boxes, class_ids = parse_annotation(txt_file)\n",
    "    image_paths.append(image_path)\n",
    "    bbox.append(boxes)\n",
    "    classes.append(class_ids)\n",
    "\n",
    "print(\"Lenght of imgaes list\",  len(image_paths))\n",
    "print(\"Lenght of bbox list\",    len(bbox))\n",
    "print(\"Lenght of classes list\", len(classes))\n",
    "\n",
    "bbox = tf.ragged.constant(bbox)\n",
    "classes = tf.ragged.constant(classes)\n",
    "image_paths = tf.ragged.constant(image_paths)\n",
    "\n",
    "data = tf.data.Dataset.from_tensor_slices((image_paths, classes, bbox))\n",
    "\n",
    "# Determine the number of validation samples\n",
    "num_valtest = int(len(txt_files) * SPLIT_RATIO)\n",
    "\n",
    "# Split the dataset into train and validation sets\n",
    "valtest_data = data.take(num_valtest+num_valtest)\n",
    "\n",
    "val_data = valtest_data.take(num_valtest)\n",
    "test_data = valtest_data.skip(num_valtest)\n",
    "\n",
    "train_data = data.skip(num_valtest+num_valtest)\n",
    "\n",
    "# def load_image(image_path):\n",
    "#     image = tf.io.read_file(image_path)\n",
    "#     image = tf.image.decode_png(image, channels=3)\n",
    "#     return image\n",
    "\n",
    "def load_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)  # Decode as a 3-channel RGB image\n",
    "    image = tf.image.resize(image, (640, 640))  # Resize image to a fixed size\n",
    "    image = tf.cast(image, tf.float32)  # Convert to float32 for model input\n",
    "    return image\n",
    "\n",
    "\n",
    "def load_dataset(image_path, classes, bbox):\n",
    "    # Read Image\n",
    "    image = load_image(image_path)\n",
    "    bounding_boxes = {\n",
    "        \"classes\": tf.cast(classes, dtype=tf.float32),\n",
    "        \"boxes\": bbox,\n",
    "    }\n",
    "    return {\"images\": tf.cast(image, tf.float32), \"bounding_boxes\": bounding_boxes}\n",
    "augmenter = keras.Sequential(\n",
    "    layers=[\n",
    "        keras_cv.layers.RandomFlip(mode=\"horizontal\", bounding_box_format=\"xywh\"),\n",
    "        # keras_cv.layers.RandomShear( # crosscheck with visualisation shows that shear make only whorse\n",
    "        #     x_factor=0.2, y_factor=0.2, bounding_box_format=\"xywh\"\n",
    "        # ),\n",
    "        keras_cv.layers.JitteredResize(\n",
    "            target_size=(640, 640), scale_factor=(1, 1), bounding_box_format=\"xywh\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "train_ds = train_data.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.shuffle(BATCH_SIZE * 4)\n",
    "train_ds = train_ds.ragged_batch(BATCH_SIZE, drop_remainder=False)\n",
    "train_ds = train_ds.map(augmenter, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "resizing = keras_cv.layers.JitteredResize(\n",
    "    target_size=(640, 640),\n",
    "    scale_factor=(1, 1),\n",
    "    bounding_box_format=\"xywh\",\n",
    ")\n",
    "\n",
    "val_ds = val_data.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.shuffle(BATCH_SIZE * 4)\n",
    "val_ds = val_ds.ragged_batch(BATCH_SIZE, drop_remainder=False)\n",
    "val_ds = val_ds.map(resizing, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "def visualize_dataset(inputs, value_range, rows, cols, bounding_box_format):\n",
    "\n",
    "    inputs = next(iter(inputs.take(1)))\n",
    "    images, bounding_boxes = inputs[\"images\"], inputs[\"bounding_boxes\"]\n",
    "    visualization.plot_bounding_box_gallery(\n",
    "        images,\n",
    "        value_range=value_range,\n",
    "        rows=rows,\n",
    "        cols=cols,\n",
    "        y_true=bounding_boxes,\n",
    "        scale=5,\n",
    "        font_scale=0.7,\n",
    "        bounding_box_format=bounding_box_format,\n",
    "        class_mapping=class_mapping,\n",
    "    )\n",
    "\n",
    "\n",
    "visualize_dataset(\n",
    "    train_ds, bounding_box_format=\"xywh\", value_range=(0, 255), rows=2, cols=2\n",
    ")\n",
    "\n",
    "visualize_dataset(\n",
    "    val_ds, bounding_box_format=\"xywh\", value_range=(0, 255), rows=2, cols=2\n",
    ")\n",
    "def dict_to_tuple(inputs):\n",
    "    return inputs[\"images\"], bounding_box.to_dense(inputs[\"bounding_boxes\"], max_boxes=32)\n",
    "\n",
    "\n",
    "train_ds = train_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = val_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "yolo = keras_cv.models.YOLOV8Detector.from_preset(\n",
    "    \"mobilenet_v3_small_imagenet\",\n",
    "    bounding_box_format=\"xywh\",\n",
    "    num_classes=len(class_mapping),\n",
    "    input_shape = (640, 640, 3),\n",
    "    load_weights=True)\n",
    "\n",
    "isLayersTrainable = False\n",
    "\n",
    "for layer in yolo.layers:\n",
    "\n",
    "    if layer.name == \"tf.concat_5\" and not isLayersTrainable:\n",
    "        isLayersTrainable = True\n",
    "\n",
    "    if isLayersTrainable:\n",
    "        layer.trainable=True\n",
    "    else:\n",
    "        layer.trainable=False\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    global_clipnorm=GLOBAL_CLIPNORM,\n",
    ")\n",
    "\n",
    "yolo.compile(\n",
    "    optimizer=optimizer, classification_loss=\"binary_crossentropy\", box_loss=\"ciou\"\n",
    ")\n",
    "\n",
    "class EvaluateCOCOMetricsCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, data, save_dir):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.metrics = keras_cv.metrics.BoxCOCOMetrics(\n",
    "            bounding_box_format=\"xywh\",\n",
    "            evaluate_freq=1e9,\n",
    "        )\n",
    "\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self.metrics.reset_state()\n",
    "        for batch in self.data:\n",
    "            images, y_true = batch[0], batch[1]\n",
    "            y_pred = self.model.predict(images, verbose=0)\n",
    "            self.metrics.update_state(y_true, y_pred)\n",
    "\n",
    "        metrics = self.metrics.result(force=True)\n",
    "        logs.update(metrics)\n",
    "\n",
    "        # save logs\n",
    "        with open(os.path.join(self.save_dir, f\"epoch_{epoch}_logs.txt\"), \"w\") as file:\n",
    "            for key, value in logs.items():\n",
    "\n",
    "                if isinstance(value, tf.Tensor):\n",
    "                    file.write(key + \":\" + str(value.numpy()) + \"\\n\")\n",
    "                else:\n",
    "                    file.write(key + \":\" + str(value) + \"\\n\")\n",
    "\n",
    "\n",
    "        # save model\n",
    "        self.model.save(os.path.join(self.save_dir, f\"epoch_{epoch}_model.keras\"))\n",
    "\n",
    "        return logs\n",
    "history = yolo.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    callbacks=[EvaluateCOCOMetricsCallback(val_ds, model_store_dir)],\n",
    ")\n",
    "filenames = os.listdir(model_store_dir)\n",
    "filenames = [filename for filename in filenames if \".txt\" in filename]\n",
    "\n",
    "logs = {}\n",
    "\n",
    "with open(os.path.join(model_store_dir, filenames[0]), \"r\") as file:\n",
    "\n",
    "    for line in file:\n",
    "        key = line.split(\":\")[0]\n",
    "\n",
    "        logs[key] = []\n",
    "\n",
    "for epoch in range(len(filenames)):\n",
    "\n",
    "    filename = f\"epoch_{epoch}_logs.txt\"\n",
    "\n",
    "    with open(os.path.join(model_store_dir, filename), \"r\") as file:\n",
    "\n",
    "        for line in file:\n",
    "\n",
    "            key, value = line.split(\":\")\n",
    "            value = float(value)\n",
    "\n",
    "            logs[key].append(value)\n",
    "\n",
    "epochs  = [i+1 for i in range(len(filenames))]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for key, value in logs.items():\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs[3:], value[3:])\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(key)\n",
    "\n",
    "def evaluateCocoMetrics(model, data):\n",
    "\n",
    "    boxCOCOMetrics = keras_cv.metrics.BoxCOCOMetrics(\n",
    "        bounding_box_format=\"xywh\",\n",
    "        evaluate_freq=1e9,\n",
    "    )\n",
    "\n",
    "    boxCOCOMetrics.reset_state()\n",
    "\n",
    "    numOfSteps = tf.data.experimental.cardinality(data).numpy()\n",
    "\n",
    "    for i,batch in enumerate(data):\n",
    "        print(f\"\\r Processing step {i+1}/{numOfSteps}\", end=\"\")\n",
    "        images, y_true = batch[0], batch[1]\n",
    "        y_pred = model.predict(images, verbose=0)\n",
    "        boxCOCOMetrics.update_state(y_true, y_pred)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "    logs = boxCOCOMetrics.result(force=True)\n",
    "\n",
    "    return logs\n",
    "test_ds = test_data.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.shuffle(BATCH_SIZE * 4)\n",
    "test_ds = test_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)\n",
    "test_ds = test_ds.map(resizing, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "test_ds = test_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "BEST_EPOCH = 5\n",
    "\n",
    "model_path = os.path.join(model_store_dir, f\"epoch_{BEST_EPOCH}_model.keras\")\n",
    "yolo_best = tf.keras.models.load_model(model_path)\n",
    "\n",
    "yolo_best.compile(\n",
    "    optimizer=optimizer, classification_loss=\"binary_crossentropy\", box_loss=\"ciou\"\n",
    ")\n",
    "\n",
    "logs = yolo_best.evaluate(test_ds)\n",
    "logs = {\"loss\": logs[0],\n",
    "        \"box_loss\": logs[1],\n",
    "        \"class_loss\": logs[2]\n",
    "}\n",
    "\n",
    "logs.update( evaluateCocoMetrics(yolo_best, test_ds) )\n",
    "\n",
    "print(\"{:<27} {:<10}\".format('Metric','Value'))\n",
    "\n",
    "for key, value in logs.items():\n",
    "    if isinstance(value, tf.Tensor):\n",
    "        print(\"{:<27} {:<10}\".format(key, value.numpy()))\n",
    "    else:\n",
    "        print(\"{:<27} {:<10}\".format(key, value))\n",
    "\n",
    "def visualize_detections(model, dataset, bounding_box_format):\n",
    "    images, y_true = next(iter(dataset.take(1)))\n",
    "    y_pred = model.predict(images)\n",
    "    y_pred = bounding_box.to_ragged(y_pred)\n",
    "    visualization.plot_bounding_box_gallery(\n",
    "        images,\n",
    "        value_range=(0, 255),\n",
    "        bounding_box_format=bounding_box_format,\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        scale=4,\n",
    "        rows=2,\n",
    "        cols=2,\n",
    "        show=True,\n",
    "        font_scale=0.7,\n",
    "        class_mapping=class_mapping,\n",
    "    )\n",
    "\n",
    "\n",
    "#visualize_detections(yolo_best, dataset=val_ds, bounding_box_format=\"xywh\") \n",
    "\n",
    "train_image_paths = train_data.map(lambda image_path, _, __: image_path)\n",
    "datasetFileTrain = os.path.join(model_store_dir, \"trainDatasetFile.txt\")\n",
    "\n",
    "with open(datasetFileTrain, \"w\") as trainDataFile:\n",
    "    for image_path in train_image_paths:\n",
    "            trainDataFile.write(image_path.numpy().decode('utf-8') + \"\\n\")\n",
    "\n",
    "##########################################################################\n",
    "\n",
    "val_image_paths = val_data.map(lambda image_path, _, __: image_path)\n",
    "datasetFileVal = os.path.join(model_store_dir, \"valDatasetFile.txt\")\n",
    "\n",
    "with open(datasetFileVal, \"w\") as valDataFile:\n",
    "    for image_path in val_image_paths:\n",
    "            valDataFile.write(image_path.numpy().decode('utf-8') + \"\\n\")\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "test_image_paths = test_data.map(lambda image_path, _, __: image_path)\n",
    "datasetFileTest = os.path.join(model_store_dir, \"testDatasetFile.txt\")\n",
    "\n",
    "with open(datasetFileTest, \"w\") as testDataFile:\n",
    "    for image_path in test_image_paths:\n",
    "            testDataFile.write(image_path.numpy().decode('utf-8') + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imghdr\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def verify_jpeg_images(directory):\n",
    "    invalid_files = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.jpg', '.jpeg')):\n",
    "                file_path = os.path.join(root, file)\n",
    "                # Check file type\n",
    "                if imghdr.what(file_path) != 'jpeg':\n",
    "                    invalid_files.append((file_path, 'Incorrect file type'))\n",
    "                    continue\n",
    "                # Check for corruption\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:\n",
    "                        img.verify()  # This will raise an exception if the image is corrupted\n",
    "                except (IOError, SyntaxError) as e:\n",
    "                    invalid_files.append((file_path, 'Corrupted image'))\n",
    "    return invalid_files\n",
    "\n",
    "# Usage\n",
    "unsupported = verify_jpeg_images('/Users/vdk/Software/my_code/python/sofi/data/rad_photo_custom/imgs')\n",
    "if unsupported:\n",
    "    print(\"Issues found with the following JPEG files:\")\n",
    "    for file, reason in unsupported:\n",
    "        print(f\"{file}: {reason}\")\n",
    "else:\n",
    "    print(\"All JPEG files are valid.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def reencode_jpeg_images(directory):\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.jpg', '.jpeg')):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:\n",
    "                        rgb_img = img.convert('RGB')  # Ensure image is in RGB\n",
    "                        rgb_img.save(file_path, format='JPEG')  # Overwrite with standard JPEG\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to re-encode {file_path}: {e}\")\n",
    "\n",
    "# Usage\n",
    "reencode_jpeg_images('/Users/vdk/Software/my_code/python/sofi/data/rad_photo_custom/imgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import keras_cv\n",
    "from keras_cv import bounding_box\n",
    "from keras_cv import visualization\n",
    "\n",
    "SPLIT_RATIO = 0.1\n",
    "BATCH_SIZE = 2\n",
    "LEARNING_RATE = 0.024\n",
    "GLOBAL_CLIPNORM = 10.0\n",
    "\n",
    "dataset_dir = \"/Users/vdk/Software/my_code/python/sofi/data/rad_photo_custom/yolo_labeled_files\"\n",
    "model_store_dir = \"/Users/vdk/Software/my_code/python/sofi/data/output\"\n",
    "\n",
    "class_ids = [\n",
    "    \"With_Radiation_sign\",\n",
    "    \"Without_Radiation_sign\",\n",
    "    \"Radiation_sign\"\n",
    "]\n",
    "\n",
    "class_mapping = dict(zip(range(len(class_ids)), class_ids))\n",
    "name2classID = {value:key for key,value in class_mapping.items()}\n",
    "\n",
    "txt_files = []\n",
    "\n",
    "for r, _, f in os.walk(dataset_dir):\n",
    "    for txt_filename in f:\n",
    "        txt_files.append(os.path.join(r, txt_filename))\n",
    "txt_files = sorted(txt_files)\n",
    "random.seed(10)\n",
    "random.shuffle(txt_files)\n",
    "\n",
    "def parse_annotation(txt_file):\n",
    "\n",
    "    image_path = txt_file.split(\"/\")\n",
    "    image_path[-2] = \"imgs\"\n",
    "    image_path[-1] = image_path[-1][:-4] + \".jpg\"\n",
    "    image_path = \"/\".join(image_path)\n",
    "\n",
    "    boxes = []\n",
    "    class_ids = []\n",
    "    with open(txt_file) as file:\n",
    "\n",
    "        try:\n",
    "            for line in file:\n",
    "                lineSplit = line.split()\n",
    "                box = lineSplit[1:]\n",
    "                box = [640*float(coor) for coor in box]\n",
    "                # correct from center to edge of the box\n",
    "                box[0] -= box[2]/2\n",
    "                box[1] -= box[3]/2\n",
    "\n",
    "                boxes.append(box)\n",
    "\n",
    "\n",
    "                class_ids.append(lineSplit[0])\n",
    "        except:\n",
    "            print(f\"Filename has something wrong {txt_file}\")\n",
    "\n",
    "    return image_path, boxes, class_ids\n",
    "\n",
    "\n",
    "image_paths = []\n",
    "bbox = []\n",
    "classes = []\n",
    "for txt_file in tqdm(txt_files):\n",
    "    image_path, boxes, class_ids = parse_annotation(txt_file)\n",
    "    image_paths.append(image_path)\n",
    "    bbox.append(boxes)\n",
    "    classes.append(class_ids)\n",
    "\n",
    "print(\"Lenght of imgaes list\",  len(image_paths))\n",
    "print(\"Lenght of bbox list\",    len(bbox))\n",
    "print(\"Lenght of classes list\", len(classes))\n",
    "\n",
    "bbox = tf.ragged.constant(bbox)\n",
    "classes = tf.ragged.constant(classes)\n",
    "image_paths = tf.ragged.constant(image_paths)\n",
    "\n",
    "data = tf.data.Dataset.from_tensor_slices((image_paths, classes, bbox))\n",
    "\n",
    "\n",
    "# # Determine the number of validation samples\n",
    "# num_valtest = int(len(txt_files) * SPLIT_RATIO)\n",
    "\n",
    "# # Split the dataset into train and validation sets\n",
    "# valtest_data = data.take(num_valtest+num_valtest)\n",
    "\n",
    "# val_data = valtest_data.take(num_valtest)\n",
    "# test_data = valtest_data.skip(num_valtest)\n",
    "\n",
    "# train_data = data.skip(num_valtest+num_valtest)\n",
    "\n",
    "# def load_image(image_path):\n",
    "#     image = tf.io.read_file(image_path)\n",
    "#     image = tf.image.decode_png(image, channels=3)\n",
    "#     return image\n",
    "\n",
    "\n",
    "# def load_dataset(image_path, classes, bbox):\n",
    "#     # Read Image\n",
    "#     image = load_image(image_path)\n",
    "#     bounding_boxes = {\n",
    "#         \"classes\": tf.cast(classes, dtype=tf.float32),\n",
    "#         \"boxes\": bbox,\n",
    "#     }\n",
    "#     return {\"images\": tf.cast(image, tf.float32), \"bounding_boxes\": bounding_boxes}\n",
    "# augmenter = keras.Sequential(\n",
    "#     layers=[\n",
    "#         keras_cv.layers.RandomFlip(mode=\"horizontal\", bounding_box_format=\"xywh\"),\n",
    "#         # keras_cv.layers.RandomShear( # crosscheck with visualisation shows that shear make only whorse\n",
    "#         #     x_factor=0.2, y_factor=0.2, bounding_box_format=\"xywh\"\n",
    "#         # ),\n",
    "#         keras_cv.layers.JitteredResize(\n",
    "#             target_size=(640, 640), scale_factor=(1, 1), bounding_box_format=\"xywh\"\n",
    "#         ),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# train_ds = train_data.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# train_ds = train_ds.shuffle(BATCH_SIZE * 4)\n",
    "# train_ds = train_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)\n",
    "# train_ds = train_ds.map(augmenter, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# resizing = keras_cv.layers.JitteredResize(\n",
    "#     target_size=(640, 640),\n",
    "#     scale_factor=(1, 1),\n",
    "#     bounding_box_format=\"xywh\",\n",
    "# )\n",
    "\n",
    "# val_ds = val_data.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# val_ds = val_ds.shuffle(BATCH_SIZE * 4)\n",
    "# val_ds = val_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)\n",
    "# val_ds = val_ds.map(resizing, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# def visualize_dataset(inputs, value_range, rows, cols, bounding_box_format):\n",
    "\n",
    "#     inputs = next(iter(inputs.take(1)))\n",
    "#     images, bounding_boxes = inputs[\"images\"], inputs[\"bounding_boxes\"]\n",
    "#     visualization.plot_bounding_box_gallery(\n",
    "#         images,\n",
    "#         value_range=value_range,\n",
    "#         rows=rows,\n",
    "#         cols=cols,\n",
    "#         y_true=bounding_boxes,\n",
    "#         scale=5,\n",
    "#         font_scale=0.7,\n",
    "#         bounding_box_format=bounding_box_format,\n",
    "#         class_mapping=class_mapping,\n",
    "#     )\n",
    "\n",
    "\n",
    "# visualize_dataset(\n",
    "#     train_ds, bounding_box_format=\"xywh\", value_range=(0, 255), rows=2, cols=2\n",
    "# )\n",
    "\n",
    "# visualize_dataset(\n",
    "#     val_ds, bounding_box_format=\"xywh\", value_range=(0, 255), rows=2, cols=2\n",
    "# )\n",
    "# def dict_to_tuple(inputs):\n",
    "#     return inputs[\"images\"], bounding_box.to_dense(inputs[\"bounding_boxes\"], max_boxes=32)\n",
    "\n",
    "\n",
    "# train_ds = train_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# val_ds = val_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# yolo = keras_cv.models.YOLOV8Detector.from_preset(\n",
    "#     \"mobilenet_v3_small_imagenet\",\n",
    "#     bounding_box_format=\"xywh\",\n",
    "#     num_classes=len(class_mapping),\n",
    "#     input_shape = (640, 640, 3),\n",
    "#     load_weights=True)\n",
    "\n",
    "# isLayersTrainable = False\n",
    "\n",
    "# for layer in yolo.layers:\n",
    "\n",
    "#     if layer.name == \"tf.concat_5\" and not isLayersTrainable:\n",
    "#         isLayersTrainable = True\n",
    "\n",
    "#     if isLayersTrainable:\n",
    "#         layer.trainable=True\n",
    "#     else:\n",
    "#         layer.trainable=False\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(\n",
    "#     learning_rate=LEARNING_RATE,\n",
    "#     global_clipnorm=GLOBAL_CLIPNORM,\n",
    "# )\n",
    "\n",
    "# yolo.compile(\n",
    "#     optimizer=optimizer, classification_loss=\"binary_crossentropy\", box_loss=\"ciou\"\n",
    "# )\n",
    "\n",
    "# class EvaluateCOCOMetricsCallback(keras.callbacks.Callback):\n",
    "#     def __init__(self, data, save_dir):\n",
    "#         super().__init__()\n",
    "#         self.data = data\n",
    "#         self.metrics = keras_cv.metrics.BoxCOCOMetrics(\n",
    "#             bounding_box_format=\"xywh\",\n",
    "#             evaluate_freq=1e9,\n",
    "#         )\n",
    "\n",
    "#         self.save_dir = save_dir\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs):\n",
    "#         self.metrics.reset_state()\n",
    "#         for batch in self.data:\n",
    "#             images, y_true = batch[0], batch[1]\n",
    "#             y_pred = self.model.predict(images, verbose=0)\n",
    "#             self.metrics.update_state(y_true, y_pred)\n",
    "\n",
    "#         metrics = self.metrics.result(force=True)\n",
    "#         logs.update(metrics)\n",
    "\n",
    "#         # save logs\n",
    "#         with open(os.path.join(self.save_dir, f\"epoch_{epoch}_logs.txt\"), \"w\") as file:\n",
    "#             for key, value in logs.items():\n",
    "\n",
    "#                 if isinstance(value, tf.Tensor):\n",
    "#                     file.write(key + \":\" + str(value.numpy()) + \"\\n\")\n",
    "#                 else:\n",
    "#                     file.write(key + \":\" + str(value) + \"\\n\")\n",
    "\n",
    "\n",
    "#         # save model\n",
    "#         self.model.save(os.path.join(self.save_dir, f\"epoch_{epoch}_model.keras\"))\n",
    "\n",
    "#         return logs\n",
    "# history = yolo.fit(\n",
    "#     train_ds,\n",
    "#     validation_data=val_ds,\n",
    "#     epochs=50,\n",
    "#     callbacks=[EvaluateCOCOMetricsCallback(val_ds, model_store_dir)],\n",
    "# )\n",
    "# filenames = os.listdir(model_store_dir)\n",
    "# filenames = [filename for filename in filenames if \".txt\" in filename]\n",
    "\n",
    "# logs = {}\n",
    "\n",
    "# with open(os.path.join(model_store_dir, filenames[0]), \"r\") as file:\n",
    "\n",
    "#     for line in file:\n",
    "#         key = line.split(\":\")[0]\n",
    "\n",
    "#         logs[key] = []\n",
    "\n",
    "# for epoch in range(len(filenames)):\n",
    "\n",
    "#     filename = f\"epoch_{epoch}_logs.txt\"\n",
    "\n",
    "#     with open(os.path.join(model_store_dir, filename), \"r\") as file:\n",
    "\n",
    "#         for line in file:\n",
    "\n",
    "#             key, value = line.split(\":\")\n",
    "#             value = float(value)\n",
    "\n",
    "#             logs[key].append(value)\n",
    "\n",
    "# epochs  = [i+1 for i in range(len(filenames))]\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# for key, value in logs.items():\n",
    "\n",
    "#     plt.figure()\n",
    "#     plt.plot(epochs[3:], value[3:])\n",
    "#     plt.xlabel(\"epoch\")\n",
    "#     plt.ylabel(key)\n",
    "\n",
    "# def evaluateCocoMetrics(model, data):\n",
    "\n",
    "#     boxCOCOMetrics = keras_cv.metrics.BoxCOCOMetrics(\n",
    "#         bounding_box_format=\"xywh\",\n",
    "#         evaluate_freq=1e9,\n",
    "#     )\n",
    "\n",
    "#     boxCOCOMetrics.reset_state()\n",
    "\n",
    "#     numOfSteps = tf.data.experimental.cardinality(data).numpy()\n",
    "\n",
    "#     for i,batch in enumerate(data):\n",
    "#         print(f\"\\r Processing step {i+1}/{numOfSteps}\", end=\"\")\n",
    "#         images, y_true = batch[0], batch[1]\n",
    "#         y_pred = model.predict(images, verbose=0)\n",
    "#         boxCOCOMetrics.update_state(y_true, y_pred)\n",
    "#     print(\"\\n\")\n",
    "\n",
    "\n",
    "#     logs = boxCOCOMetrics.result(force=True)\n",
    "\n",
    "#     return logs\n",
    "# test_ds = test_data.map(load_dataset, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# test_ds = test_ds.shuffle(BATCH_SIZE * 4)\n",
    "# test_ds = test_ds.ragged_batch(BATCH_SIZE, drop_remainder=True)\n",
    "# test_ds = test_ds.map(resizing, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# test_ds = test_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "# test_ds = test_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# BEST_EPOCH = 48\n",
    "\n",
    "# model_path = os.path.join(model_store_dir, f\"epoch_{BEST_EPOCH}_model.keras\")\n",
    "# yolo_best = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# yolo_best.compile(\n",
    "#     optimizer=optimizer, classification_loss=\"binary_crossentropy\", box_loss=\"ciou\"\n",
    "# )\n",
    "\n",
    "# logs = yolo_best.evaluate(test_ds)\n",
    "# logs = {\"loss\": logs[0],\n",
    "#         \"box_loss\": logs[1],\n",
    "#         \"class_loss\": logs[2]\n",
    "# }\n",
    "\n",
    "# logs.update( evaluateCocoMetrics(yolo_best, test_ds) )\n",
    "\n",
    "# print(\"{:<27} {:<10}\".format('Metric','Value'))\n",
    "\n",
    "# for key, value in logs.items():\n",
    "#     if isinstance(value, tf.Tensor):\n",
    "#         print(\"{:<27} {:<10}\".format(key, value.numpy()))\n",
    "#     else:\n",
    "#         print(\"{:<27} {:<10}\".format(key, value))\n",
    "\n",
    "# def visualize_detections(model, dataset, bounding_box_format):\n",
    "#     images, y_true = next(iter(dataset.take(1)))\n",
    "#     y_pred = model.predict(images)\n",
    "#     y_pred = bounding_box.to_ragged(y_pred)\n",
    "#     visualization.plot_bounding_box_gallery(\n",
    "#         images,\n",
    "#         value_range=(0, 255),\n",
    "#         bounding_box_format=bounding_box_format,\n",
    "#         y_true=y_true,\n",
    "#         y_pred=y_pred,\n",
    "#         scale=4,\n",
    "#         rows=2,\n",
    "#         cols=2,\n",
    "#         show=True,\n",
    "#         font_scale=0.7,\n",
    "#         class_mapping=class_mapping,\n",
    "#     )\n",
    "\n",
    "\n",
    "# visualize_detections(yolo_best, dataset=val_ds, bounding_box_format=\"xywh\")\n",
    "\n",
    "# train_image_paths = train_data.map(lambda image_path, _, __: image_path)\n",
    "# datasetFileTrain = os.path.join(model_store_dir, \"trainDatasetFile.txt\")\n",
    "\n",
    "# with open(datasetFileTrain, \"w\") as trainDataFile:\n",
    "#     for image_path in train_image_paths:\n",
    "#             trainDataFile.write(image_path.numpy().decode('utf-8') + \"\\n\")\n",
    "\n",
    "# ##########################################################################\n",
    "\n",
    "# val_image_paths = val_data.map(lambda image_path, _, __: image_path)\n",
    "# datasetFileVal = os.path.join(model_store_dir, \"valDatasetFile.txt\")\n",
    "\n",
    "# with open(datasetFileVal, \"w\") as valDataFile:\n",
    "#     for image_path in val_image_paths:\n",
    "#             valDataFile.write(image_path.numpy().decode('utf-8') + \"\\n\")\n",
    "\n",
    "# #########################################################################\n",
    "\n",
    "# test_image_paths = test_data.map(lambda image_path, _, __: image_path)\n",
    "# datasetFileTest = os.path.join(model_store_dir, \"testDatasetFile.txt\")\n",
    "\n",
    "# with open(datasetFileTest, \"w\") as testDataFile:\n",
    "#     for image_path in test_image_paths:\n",
    "#             testDataFile.write(image_path.numpy().decode('utf-8') + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path, class_id, bbox in data.take(5):  # Takes first 5 elements\n",
    "    print(\"===========================\")\n",
    "    print(\"Image Path:\", image_path.numpy().decode('utf-8'))\n",
    "    print(\"Class ID:\", class_id.numpy()[0].decode('utf-8'))\n",
    "    print(\"Bounding Box:\", bbox.numpy()[0])\n",
    "    print(\"===========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_files(directory):\n",
    "    # Iterate over all files in the specified directory\n",
    "    for filename in os.listdir(directory):\n",
    "        # Check if the filename contains spaces\n",
    "        if ' ' in filename:\n",
    "            # Create the new filename by replacing spaces with underscores\n",
    "            new_filename = filename.replace(' ', '_')\n",
    "            \n",
    "            # Define full file paths\n",
    "            src = os.path.join(directory, filename)\n",
    "            dst = os.path.join(directory, new_filename)\n",
    "            \n",
    "            # Rename the file\n",
    "            os.rename(src, dst)\n",
    "            print(f\"Renamed: '{filename}' -> '{new_filename}'\")\n",
    "\n",
    "rename_files('/Users/vdk/Software/my_code/python/sofi/data/rad_photo/yolo_labeled_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def delete_jpg_files(directory):\n",
    "    # Iterate over all entries in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.lower().endswith('.jpg'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "                print(f\"Deleted: {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_jpg_files('/Users/vdk/Software/my_code/python/sofi/data/rad_photo/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def extract_lines(input_dir):\n",
    "    \"\"\"\n",
    "    Extracts lines starting with '2' from 'with_label_*.txt' files\n",
    "    and writes them to corresponding 'sign_*.txt' files.\n",
    "    \n",
    "    :param input_dir: Path to the directory containing the files.\n",
    "    \"\"\"\n",
    "    # Pattern to match 'with_label_*.txt' files\n",
    "    pattern = os.path.join(input_dir, 'with_label_*.txt')\n",
    "    \n",
    "    # Retrieve all matching files\n",
    "    input_files = glob.glob(pattern)\n",
    "    \n",
    "    if not input_files:\n",
    "        print(f\"No files found matching pattern: {pattern}\")\n",
    "        return\n",
    "    \n",
    "    for input_file in input_files:\n",
    "        # Derive the identifier '*' from the filename\n",
    "        basename = os.path.basename(input_file)  # e.g., 'with_label_example.txt'\n",
    "        identifier = basename.replace('with_label_', '').replace('.txt', '')  # e.g., 'example'\n",
    "        \n",
    "        # Define the output filename\n",
    "        output_filename = f'sign_{identifier}.txt'\n",
    "        output_file = os.path.join(input_dir, output_filename)\n",
    "        \n",
    "        try:\n",
    "            with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "                lines_extracted = 0\n",
    "                for line in infile:\n",
    "                    if line.startswith('2'):\n",
    "                        outfile.write(line)\n",
    "                        lines_extracted += 1\n",
    "            print(f\"Processed '{input_file}': Extracted {lines_extracted} lines to '{output_filename}'\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing '{input_file}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "def extract_and_remove_lines(input_dir):\n",
    "    \"\"\"\n",
    "    Extracts lines starting with '2' from 'with_label_*.txt' files,\n",
    "    writes them to corresponding 'sign_*.txt' files,\n",
    "    and removes those lines from the original files.\n",
    "\n",
    "    :param input_dir: Path to the directory containing the files.\n",
    "    \"\"\"\n",
    "    # Pattern to match 'with_label_*.txt' files\n",
    "    pattern = os.path.join(input_dir, 'with_label_*.txt')\n",
    "    \n",
    "    # Retrieve all matching files\n",
    "    input_files = glob.glob(pattern)\n",
    "    \n",
    "    if not input_files:\n",
    "        print(f\"No files found matching pattern: {pattern}\")\n",
    "        return\n",
    "    \n",
    "    for input_file in input_files:\n",
    "        # Derive the identifier '*' from the filename\n",
    "        basename = os.path.basename(input_file)  # e.g., 'with_label_example.txt'\n",
    "        identifier = basename.replace('with_label_', '').replace('.txt', '')  # e.g., 'example'\n",
    "        \n",
    "        # Define the output filename\n",
    "        output_filename = f'sign_{identifier}.txt'\n",
    "        output_file = os.path.join(input_dir, output_filename)\n",
    "        \n",
    "        # Create a temporary file to store the modified original content\n",
    "        temp_fd, temp_path = tempfile.mkstemp(dir=input_dir, prefix='temp_', suffix='.txt')\n",
    "        \n",
    "        lines_extracted = 0\n",
    "        try:\n",
    "            with open(input_file, 'r') as infile, \\\n",
    "                 open(output_file, 'w') as outfile, \\\n",
    "                 os.fdopen(temp_fd, 'w') as temp_file:\n",
    "                \n",
    "                for line in infile:\n",
    "                    if line.startswith('2'):\n",
    "                        outfile.write(line)\n",
    "                        lines_extracted += 1\n",
    "                    else:\n",
    "                        temp_file.write(line)\n",
    "            \n",
    "            # Replace the original file with the temporary file\n",
    "            shutil.move(temp_path, input_file)\n",
    "            \n",
    "            print(f\"Processed '{input_file}': Extracted {lines_extracted} lines to '{output_filename}' and updated the original file.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Remove the temporary file in case of an error\n",
    "            os.remove(temp_path)\n",
    "            print(f\"Error processing '{input_file}': {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the directory containing the files\n",
    "    # Update this path to your target directory\n",
    "    target_directory = \"/Users/vdk/Software/my_code/python/sofi/data/yolo_labeled_files\"\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    if not os.path.isdir(target_directory):\n",
    "        print(f\"The directory '{target_directory}' does not exist.\")\n",
    "    else:\n",
    "        extract_and_remove_lines(target_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_lines('/Users/vdk/Software/my_code/python/sofi/data/yolo_labeled_files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
