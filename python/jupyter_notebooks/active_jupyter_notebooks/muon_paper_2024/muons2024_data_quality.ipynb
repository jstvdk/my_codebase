{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from astropy.coordinates import SkyCoord, AltAz, angular_separation\n",
    "import astropy.units as u\n",
    "from scipy.stats import binned_statistic\n",
    "from scipy.signal import lombscargle\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import scipy as sc\n",
    "max_diffuse_nsb_std = 2.3\n",
    "# test_file = '/Users/vdk/muons2024/v0.9-v0.10/20240228/DL1_datacheck_20240228.h5'\n",
    "# with pd.HDFStore(test_file) as hdf:\n",
    "#     # This prints a list of all group names:\n",
    "#     print(hdf.keys())\n",
    "    # print(hdf['cosmics'])\n",
    "    # if '/cosmics_intensity_spectrum' in hdf.keys():\n",
    "    #     print('hi')\n",
    "        \n",
    "import h5py \n",
    "start_date_2019 = datetime.strptime(\"2019-01-01 00:00:00.0\", \"%Y-%m-%d %H:%M:%S.%f\").timestamp()\n",
    "end_date_2019 = datetime.strptime(\"2019-12-31 00:00:00.0\", \"%Y-%m-%d %H:%M:%S.%f\").timestamp()\n",
    "    \n",
    "start_date_2020 = datetime.strptime(\"2020-01-01 00:00:00.0\", \"%Y-%m-%d %H:%M:%S.%f\").timestamp()\n",
    "end_date_2020 = datetime.strptime(\"2020-12-31 00:00:00.0\", \"%Y-%m-%d %H:%M:%S.%f\").timestamp()\n",
    "\n",
    "start_date_2021 = datetime.strptime(\"2021-01-01 00:00:00.0\", \"%Y-%m-%d %H:%M:%S.%f\").timestamp()\n",
    "end_date_2021 = datetime.strptime(\"2021-12-31 00:00:00.0\", \"%Y-%m-%d %H:%M:%S.%f\").timestamp()\n",
    "\n",
    "start_date_2022 = datetime.strptime(\"2022-01-01 00:00:00.0\", \"%Y-%m-%d %H:%M:%S.%f\").timestamp()\n",
    "end_date_2022 = datetime.strptime(\"2022-12-31 00:00:00.0\", \"%Y-%m-%d %H:%M:%S.%f\").timestamp()\n",
    "\n",
    "start_date_2023 = datetime.strptime(\"2023-01-01 00:00:00.0\", \"%Y-%m-%d %H:%M:%S.%f\").timestamp()\n",
    "end_date_2023 = datetime.strptime(\"2023-12-31 00:00:00.0\", \"%Y-%m-%d %H:%M:%S.%f\").timestamp()\n",
    "\n",
    "start_date_2024 = datetime.strptime(\"2024-01-01 00:00:00.0\", \"%Y-%m-%d %H:%M:%S.%f\").timestamp()\n",
    "end_date_2024 = datetime.strptime(\"2024-12-31 00:00:00.0\", \"%Y-%m-%d %H:%M:%S.%f\").timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datacheks only for 2024 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('/Users/vdk/muons2024/datachecks/v0.9-v0.10_datacheck_files/2024year_datacheks/DL1_datacheck_*.h5')\n",
    "files.sort()\n",
    "\n",
    "runsummary = []\n",
    "cosmics = []\n",
    "cis = []\n",
    "for file in files:\n",
    "    try:\n",
    "        runsummary.append(pd.read_hdf(file, 'runsummary'))\n",
    "        cosmics.append(pd.read_hdf(file, 'cosmics'))\n",
    "        cis.append(pd.read_hdf(file, 'cosmics_intensity_spectrum'))\n",
    "    except:\n",
    "        print(file)\n",
    "    \n",
    "cosmics_pd = pd.concat(cosmics, ignore_index=True)\n",
    "runsummary_pd = pd.concat(runsummary, ignore_index=True)\n",
    "cis_pd = pd.concat(cis, ignore_index=True)\n",
    "cosmics_pd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runsummary_pd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z,x,c = plt.hist(cis_pd['cosmics_rate_at_422_pe'],bins = 100, range = (0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Lomb-Scargle periodogram of ZD_corrected_cosmics_rate_at_422_pe vs. time\n",
    "# May eventually be useful to identify runs affected by MAGIC LIDAR shots...\n",
    "#\n",
    "\n",
    "max_lsc = []\n",
    "max_lsc_period = [] # in seconds\n",
    "for i, ri in enumerate(runlist):\n",
    "    if i%1000 == 0:\n",
    "        print(i, '/', len(runlist))\n",
    "    rvalues = cis['ZD_corrected_cosmics_rate_at_422_pe'][cis['runnumber']==ri].to_numpy()\n",
    "    tvalues = cis['time'][cis['runnumber']==ri].to_numpy()\n",
    "    tvalues -= tvalues[0]\n",
    "    freqs = np.logspace(-3, -1, 100)\n",
    "    mask = ~np.isnan(rvalues)\n",
    "    lsc = lombscargle(tvalues[mask], rvalues[mask], freqs, \n",
    "                      normalize=True, precenter=True)\n",
    "    max_lsc.append(np.nanmax(lsc))\n",
    "    if (~np.isnan(lsc)).sum() == 0:\n",
    "        max_lsc_period.append(np.nan)\n",
    "    else:\n",
    "        max_lsc_period.append(1./freqs[np.nanargmax(lsc)])\n",
    "\n",
    "max_lsc = np.array(max_lsc)\n",
    "max_lsc_period = np.array(max_lsc_period)\n",
    "\n",
    "# You may get some RuntimeWarnings, from rare data with big issues - those warnings can be safely ignored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality cuts on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_zenith = 0 * u.deg\n",
    "max_zenith = 20 * u.deg\n",
    "first_date = 20240101\n",
    "last_date  = 20240331\n",
    "max_diffuse_nsb_std = 2.3\n",
    "\n",
    "# We make a fit per subrun. Then we average the fit p-values. For good fits the pdf of P us uniform in [0,1]\n",
    "# The mean will have mean 0.5 and std dev 1/sqrt(12*Nsubruns). \n",
    "# We require a minimum value of (mean_p-0.5)*sqrt(12*Nsubruns) (in the limit of large Nsubruns would be a standard\n",
    "# gaussian of mean 0 and std dev 1)\n",
    "\n",
    "min_mean_fit_p = -3.\n",
    "\n",
    "# Lomb Scargle periodogram, to detect strange features in the dR/dI evolution within a run\n",
    "max_LS_periodogram_maxamplitude = 1e-2\n",
    "\n",
    "min_drdi_index = -2.35\n",
    "max_drdi_index = -2.1\n",
    "\n",
    "min_drdi_at_422pe = 1.5\n",
    "# We do not set a maximum for the rate, we expect all bad observation (or telescope) conditions \n",
    "# to result in lower-than-optimal rates\n",
    "\n",
    "# Minimum fraction of subruns around the mode of drdi_at_422pe (within +/-0.075) - see the find_mode \n",
    "# function below\n",
    "min_fraction_around_mode = 0.8\n",
    "\n",
    "# Maximum intensity threshold\n",
    "# This is a proxy for energy threshold (for a given zenith). the cut is not tight, because\n",
    "# even data with high threshold may be of very good quality, and valid to obtain a spectrum.\n",
    "# If one is targeting very low energies (e.g. for pulsar analysis) then it may be necessary to \n",
    "# make a stricter selection.\n",
    "max_intensity_at_half_peak_rate = 70 # p.e.\n",
    "\n",
    "# Note: The cut in intensity applied in the analyis of low-threshold (<40) data is >50 p.e. \n",
    "# The cut should be higher (to prevent biases in flux calculations) for data with higher threshold.\n",
    "# Difficult to set a general rule, but it is safer to put the cut above the peak of the cosmics \n",
    "# intensisy spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of loaded subruns:', len(cis_pd))\n",
    "print('Total number of loaded runs:', len(np.unique(cis_pd['runnumber'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain list of runnumbers and corresponding dates:\n",
    "runlist, iix = np.unique(cis_pd['runnumber'], return_index=True)\n",
    "rundate = cis_pd['yyyymmdd'][iix].to_numpy()\n",
    "\n",
    "# Remove runs in summary table which are not present in the cis table, to keep consistency between them.\n",
    "# NOTE, AM 20231117: as of now only run 8091 is missing from the cis table, because \n",
    "# its original run-wise datacheck file is faulty (possibly due to some problem at run time)\n",
    "\n",
    "for r in runsummary_pd['runnumber']:\n",
    "    if r in runlist:\n",
    "        continue\n",
    "    print('Removing run', r, 'from runsummary table!')\n",
    "    runsummary_pd.drop(np.where(runsummary_pd['runnumber']==r)[0], inplace=True)\n",
    "    runsummary_pd.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that now the runsummary entries match the runs in runlist (in the same order)\n",
    "assert(np.allclose(runlist, runsummary_pd['runnumber']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some utility functions:\n",
    "#\n",
    "# Function to find the mode (most frequent value) of an array x, using a bin width bw \n",
    "# and step dx (default=bw/100) (it is a sliding window sum)\n",
    "#\n",
    "# If return_fraction==True, then the fraction of the array's elements\n",
    "# contained in the bw-wide window around the mode is returned (instead of the \n",
    "# mode)\n",
    "#\n",
    "def find_mode(x, bw=0.15, dx=None, return_fraction=False):\n",
    "    \n",
    "    min = np.nanmin(x)\n",
    "    max = np.nanmax(x)\n",
    "    \n",
    "    if np.isnan(min):\n",
    "        return np.nan\n",
    "    if (max == min):\n",
    "        return np.nan\n",
    "    \n",
    "    if return_fraction & (max - min < bw):\n",
    "        return 1. # All values are within bw\n",
    "    \n",
    "    # If ALL data are within bw, then it does not make sense to make \n",
    "    # a sliding window. We reduce the window to one half until it becomes \n",
    "    # smaller than the range of x:\n",
    "\n",
    "    while bw > (max - min):\n",
    "        bw *= 0.5\n",
    "\n",
    "    if dx is None:\n",
    "        dx = bw / 100\n",
    "    \n",
    "    nn = int((max - min) // dx + 2)\n",
    "    cts, edges = np.histogram(x[~np.isnan(x)], bins=nn, range=(min-dx, max+dx))\n",
    "    csum = np.cumsum(cts) / np.sum(cts)\n",
    "    nsumbins = int(bw//dx)\n",
    "    running_sum = csum[nsumbins:]-csum[:-nsumbins]\n",
    "    xvalues = 0.5*(edges[nsumbins:]+edges[:-nsumbins])[:-1]\n",
    "\n",
    "    max_running_sum = np.nanmax(running_sum)\n",
    "    if np.isnan(max_running_sum):\n",
    "        return np.nan\n",
    "    \n",
    "    if return_fraction:\n",
    "        return max_running_sum\n",
    "\n",
    "    return xvalues[np.nanargmax(running_sum)]\n",
    "\n",
    "def find_fraction_in_mode(x):\n",
    "    return find_mode(x, bw=0.15, dx=None, return_fraction=True)\n",
    "\n",
    "def find_intensity_mode(x):\n",
    "    return find_mode(x, bw=40) # 40 photoelectrons sliding-window\n",
    "\n",
    "# Average RA, asumed to be in degrees\n",
    "def ra_mean(ra):\n",
    "    cosra = np.cos(ra*u.deg)\n",
    "    sinra = np.sin(ra*u.deg)\n",
    "\n",
    "    meanra = np.arctan2(sinra.mean(), cosra.mean())\n",
    "    if meanra < 0:\n",
    "        meanra += 2*np.pi*u.rad\n",
    "\n",
    "    return meanra.to_value(u.deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_span = cis_pd['runnumber'].max() - cis_pd['runnumber'].min() + 1\n",
    "runmin = cis_pd['runnumber'].min() - 0.5\n",
    "runmax = cis_pd['runnumber'].max() + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cis = cis_pd\n",
    "nonan = ~np.isnan(cis['ZD_corrected_cosmics_rate_at_422_pe'])\n",
    "mean_R422, bin_edges, _ = binned_statistic(cis['runnumber'][nonan], \n",
    "                                           cis['ZD_corrected_cosmics_rate_at_422_pe'][nonan], \n",
    "                                           statistic='mean', bins=run_span, range=(runmin, runmax))\n",
    "std_R422, _, _ = binned_statistic(cis['runnumber'][nonan], \n",
    "                                  cis['ZD_corrected_cosmics_rate_at_422_pe'][nonan], \n",
    "                                  statistic='std', bins=bin_edges)\n",
    "mode_R422, _, _ = binned_statistic(cis['runnumber'][nonan], \n",
    "                                   cis['ZD_corrected_cosmics_rate_at_422_pe'][nonan], \n",
    "                                   statistic=find_mode, bins=bin_edges)\n",
    "fraction_around_mode_R422, _, _ = binned_statistic(cis['runnumber'][nonan], \n",
    "                                                   cis['ZD_corrected_cosmics_rate_at_422_pe'][nonan], \n",
    "                                                   statistic=find_fraction_in_mode, bins=bin_edges)\n",
    "\n",
    "\n",
    "nonan = (cis['intensity_at_reference_rate'] < 1000) # this rempoves nans but also rare rogue values\n",
    "mean_intensity_at_reference_rate, _, _ =  binned_statistic(cis['runnumber'][nonan], \n",
    "                                                           cis['intensity_at_reference_rate'][nonan], \n",
    "                                                           statistic='mean', bins=bin_edges)\n",
    "std_intensity_at_reference_rate, _, _ =  binned_statistic(cis['runnumber'][nonan], \n",
    "                                                          cis['intensity_at_reference_rate'][nonan], \n",
    "                                                          statistic='std', bins=bin_edges)\n",
    "\n",
    "mean_light_yield, _, _ = binned_statistic(cis['runnumber'][nonan], \n",
    "                                          cis['light_yield'][nonan], \n",
    "                                          statistic='mean', bins=run_span, range=(runmin, runmax))\n",
    "std_light_yield, _, _ = binned_statistic(cis['runnumber'][nonan], \n",
    "                                         cis['light_yield'][nonan], \n",
    "                                         statistic='std', bins=run_span, range=(runmin, runmax))\n",
    "\n",
    "nonan = ~np.isnan(cis['ZD_corrected_cosmics_spectral_index'])\n",
    "mean_index, _, _ = binned_statistic(cis['runnumber'][nonan], \n",
    "                                    cis['ZD_corrected_cosmics_spectral_index'][nonan], \n",
    "                                           statistic='mean', bins=run_span, range=(runmin, runmax))\n",
    "std_index, _, _ = binned_statistic(cis['runnumber'][nonan], \n",
    "                                   cis['ZD_corrected_cosmics_spectral_index'][nonan], \n",
    "                                           statistic='std', bins=run_span, range=(runmin, runmax))\n",
    "\n",
    "\n",
    "\n",
    "# Note: the P-value of the (subrun-wise) power-law fits to the intensity spectra is properly distributed \n",
    "# (uniform from 0 to 1) for practically all subruns. Note that the run-averaged P-value no longer has a \n",
    "# uniform distribution! For good runs it is a gaussuan-ish distribution around 0.5 (central limit theorem!)\n",
    "mean_fit_p_value, _, _ =  binned_statistic(cis['runnumber'][nonan], \n",
    "                                           cis['intensity_spectrum_fit_p_value'][nonan], \n",
    "                                           statistic='mean', bins=bin_edges)\n",
    "\n",
    "nonan = ~np.isnan(cis['ZD_corrected_intensity_at_half_peak_rate'])\n",
    "mean_intensity_threshold, _, _ =  binned_statistic(cis['runnumber'][nonan], \n",
    "                                                   cis['ZD_corrected_intensity_at_half_peak_rate'][nonan], \n",
    "                                                   statistic='mean', bins=bin_edges)\n",
    "std_intensity_threshold, _, _ =  binned_statistic(cis['runnumber'][nonan], \n",
    "                                                  cis['ZD_corrected_intensity_at_half_peak_rate'][nonan], \n",
    "                                                  statistic='std', bins=bin_edges)\n",
    "\n",
    "nonan = ~np.isnan(cis['intensity_at_peak_rate'])\n",
    "# NOTE: THE INTENSITIES AT PEAK RATE ARE NOT ZD-CORRECTED! THIS IS BECAUSE WE DO NOT USE IT FOR THE \n",
    "# QUALITY SELECTION, BUT ONLY TO ESTIMATE WHAT INTENSITY CUT MAY BE REASONABLE TO USE IN LATER ANALYSIS!\n",
    "mean_intensity_at_peak_rate, _, _ =  binned_statistic(cis['runnumber'][nonan], \n",
    "                                                      cis['intensity_at_peak_rate'][nonan], \n",
    "                                                      statistic='mean', bins=bin_edges)\n",
    "std_intensity_at_peak_rate, _, _ =  binned_statistic(cis['runnumber'][nonan], \n",
    "                                                  cis['intensity_at_peak_rate'][nonan], \n",
    "                                                  statistic='std', bins=bin_edges)\n",
    "\n",
    "\n",
    "\n",
    "mean_ra, _, _  = binned_statistic(cis['runnumber'], cis['ra_tel'], statistic=ra_mean, bins=bin_edges)\n",
    "mean_dec, _, _ = binned_statistic(cis['runnumber'], cis['dec_tel'], statistic='mean', bins=bin_edges)\n",
    "std_dec, _, _ = binned_statistic(cis['runnumber'], cis['dec_tel'], statistic='std', bins=bin_edges)\n",
    "# We do not compute std_ra - it is not totally straightforward because of 0=360 deg...\n",
    "\n",
    "mean_coszd, _, _ = binned_statistic(cis['runnumber'], cis['cos_zenith'], statistic=ra_mean, bins=bin_edges)\n",
    "\n",
    "nonan = ~np.isnan(cis['diffuse_nsb_std'])\n",
    "mean_diffuse_nsb_std, _ , _ = binned_statistic(cis['runnumber'][nonan], \n",
    "                                               cis['diffuse_nsb_std'][nonan], \n",
    "                                               statistic='mean', bins=bin_edges)\n",
    "\n",
    "\n",
    "nsubruns, _ = np.histogram(cis['runnumber'], bins=bin_edges)\n",
    "run_exists = nsubruns>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert((nsubruns>0).sum() == max_lsc.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"empty entries\" (i.e. removes run numbers which are not in loaded sample,\n",
    "# e.g. because do not correspond to sky runs)\n",
    "\n",
    "mean_R422 = mean_R422[run_exists]\n",
    "std_R422  = std_R422[run_exists]\n",
    "mode_R422 = mode_R422[run_exists]\n",
    "mean_intensity_at_reference_rate = mean_intensity_at_reference_rate[run_exists]\n",
    "std_intensity_at_reference_rate = std_intensity_at_reference_rate[run_exists]\n",
    "fraction_around_mode_R422 = fraction_around_mode_R422[run_exists]\n",
    "mean_light_yield = mean_light_yield[run_exists]\n",
    "std_light_yield = std_light_yield[run_exists]\n",
    "mean_index = mean_index[run_exists]\n",
    "std_index = std_index[run_exists]\n",
    "mean_intensity_threshold = mean_intensity_threshold[run_exists]\n",
    "std_intensity_threshold = std_intensity_threshold[run_exists]\n",
    "mean_intensity_at_peak_rate = mean_intensity_at_peak_rate[run_exists]\n",
    "std_intensity_at_peak_rate = std_intensity_at_peak_rate[run_exists]\n",
    "mean_ra = mean_ra[run_exists]\n",
    "mean_dec = mean_dec[run_exists]\n",
    "std_dec = std_dec[run_exists]\n",
    "mean_coszd = mean_coszd[run_exists]\n",
    "mean_diffuse_nsb_std = mean_diffuse_nsb_std[run_exists]\n",
    "mean_fit_p_value = mean_fit_p_value[run_exists]\n",
    "nsubruns = nsubruns[run_exists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runsummary = runsummary_pd\n",
    "# Define here all the selection masks using the values set by the user above.\n",
    "# Basic selection: select only runs with in which both types of interleaved events are present:\n",
    "require_interleaved_pedestals = True\n",
    "require_interleaved_flatfield = True\n",
    "source_coordinates = None\n",
    "min_angle_to_source = None\n",
    "max_angle_to_source = None\n",
    "max_pointing_dec_std = 0.01 # deg\n",
    "\n",
    "interleaved_ok_selection = np.array(runlist.size*[True]) \n",
    "\n",
    "if require_interleaved_flatfield:\n",
    "    interleaved_ok_selection &= (runsummary['num_flatfield'] > 0).to_numpy()\n",
    "if require_interleaved_pedestals:\n",
    "    interleaved_ok_selection &= (runsummary['num_pedestals'] > 0).to_numpy()\n",
    "# interleaved_ok means just that some events were identified as interleaved FF and pedestal!\n",
    "    \n",
    "telescope_pointing = SkyCoord(ra=mean_ra*u.deg, dec=mean_dec*u.deg)\n",
    "\n",
    "skyregion_selection = np.array(runlist.size*[True]) # All Sky, if no source selection\n",
    "\n",
    "if source_coordinates != None:\n",
    "    angular_distance = source_coordinates.separation(telescope_pointing)\n",
    "    skyregion_selection = (angular_distance > min_angle_to_source) & (angular_distance < max_angle_to_source)\n",
    "\n",
    "pointing_stability_selection = std_dec < max_pointing_dec_std # Stable pointing\n",
    "    \n",
    "maxcoszd = np.cos(min_zenith)\n",
    "mincoszd = np.cos(max_zenith)\n",
    "# Note that the zenith limit is done with the run's mean, so there will be some events beyond the limits:\n",
    "zd_selection = (mean_coszd > mincoszd) & (mean_coszd < maxcoszd)\n",
    "\n",
    "nsb_selection = mean_diffuse_nsb_std < max_diffuse_nsb_std\n",
    "\n",
    "date_selection = (rundate >= first_date) & (rundate <= last_date)\n",
    "\n",
    "# P-value for good fits is distributed uniformly between 0 and 1 (which has std dev = 1/sqrt(12)). \n",
    "# So the mean of N such quantities is distributed (for N large) approximately as a a gaussian of \n",
    "# mean 0.5 and std dev = 1/sqrt(12*N). The cut below removes runs for which the power-law fits of\n",
    "# the cosmic rays intensity spectra, dR/dI, are (in average) poor:\n",
    "p_value_selection = (mean_fit_p_value-0.5)*(12*nsubruns)**0.5 > min_mean_fit_p\n",
    "\n",
    "LS_periodogram_selection = max_lsc < max_LS_periodogram_maxamplitude\n",
    "\n",
    "drdi_index_selection = (mean_index > min_drdi_index) & (mean_index < max_drdi_index) \n",
    "\n",
    "# the dR/dI rate selection includes a condition on its stability during the run. We require a \n",
    "# minimum fraction \"min_fraction_around_mode\" (defined above) of the subruns to be within +/- 0.075 of \n",
    "# the mode. This is to identify runs with large variations (sometimes due to spurious sources of triggers,\n",
    "# like e.g. car flashes or the MAGIC LIDAR)\n",
    "drdi_rate_selection = (mean_R422 > min_drdi_at_422pe) & (fraction_around_mode_R422 > min_fraction_around_mode)\n",
    "\n",
    "intensity_threshold_selection = mean_intensity_threshold < max_intensity_at_half_peak_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 15))\n",
    "\n",
    "\n",
    "fig.add_subplot(5, 2, 1)\n",
    "# Pointing stability\n",
    "cc, bb, _ = plt.hist(std_dec, bins=250, range=(0,0.05), label='All data',\n",
    "                    log=True, color='lightgrey', density=True)\n",
    "plt.hist(std_dec[interleaved_ok_selection & skyregion_selection & date_selection], bins=bb,\n",
    "         label='Runs for selected\\n source & dates',\n",
    "         log=True, density=True, histtype='step')\n",
    "\n",
    "plt.plot([max_pointing_dec_std, max_pointing_dec_std], [0, cc.max()], '--', label='Maximum allowed', \n",
    "         color='red')\n",
    "plt.xlabel('Declination std dev within run (degrees)')\n",
    "plt.ylabel('number of runs (normalized)')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "fig.add_subplot(5, 2, 2)\n",
    "cc, bb, _ = plt.hist(np.rad2deg(np.arccos(mean_coszd)), bins=180, range=(0,90), label='All data',\n",
    "                     color='lightgrey', density=True)\n",
    "\n",
    "plt.hist(np.rad2deg(np.arccos(mean_coszd))[interleaved_ok_selection & skyregion_selection & date_selection], \n",
    "         bins=bb, label='Runs for selected\\n source & dates',\n",
    "         density=True, histtype='step')\n",
    "\n",
    "plt.plot([max_zenith.to_value(u.deg), max_zenith.to_value(u.deg)], \n",
    "         [0, cc.max()], '--', label='Maximum allowed', color='red')\n",
    "plt.plot([min_zenith.to_value(u.deg), min_zenith.to_value(u.deg)], \n",
    "         [0, cc.max()], '--', label='Minimum allowed', color='green')\n",
    "\n",
    "plt.xlabel('Zenith angle (degrees)')\n",
    "plt.ylabel('number of runs (normalized)')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "fig.add_subplot(5, 2, 3)\n",
    "cc, bb, _ = plt.hist(mean_diffuse_nsb_std, bins=200, range=(0,10), label='All data',\n",
    "                     color='lightgrey', density=True)\n",
    "\n",
    "plt.hist(mean_diffuse_nsb_std[interleaved_ok_selection & skyregion_selection & date_selection], bins=bb,\n",
    "         label='Runs for selected\\n source & dates',\n",
    "         density=True, histtype='step')\n",
    "\n",
    "plt.plot([max_diffuse_nsb_std, max_diffuse_nsb_std], \n",
    "         [0, cc.max()], '--', label='Maximum allowed', color='red')\n",
    "plt.xlabel('Diffuse NSB std dev (p.e.)')\n",
    "plt.ylabel('number of runs (normalized)')\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(5, 2, 4)\n",
    "cc, bb, _ = plt.hist((mean_fit_p_value-0.5)*(12*nsubruns)**0.5, \n",
    "                     bins=150, range=(-6,9), label='All data',\n",
    "                     color='lightgrey', density=True)\n",
    "plt.hist(((mean_fit_p_value-0.5)*(12*nsubruns)**0.5)[interleaved_ok_selection & \n",
    "                                                     skyregion_selection & date_selection], \n",
    "         bins=bb, label='Runs for selected\\n source & dates',\n",
    "         density=True, histtype='step')\n",
    "plt.plot([min_mean_fit_p, min_mean_fit_p], \n",
    "         [0, cc.max()], '--', label='Minimum allowed', color='green')\n",
    "plt.xlabel('(mean_dR/dI_fit_P_value-0.5)/sqrt(12*nsubruns)')\n",
    "plt.ylabel('number of runs (normalized)')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "fig.add_subplot(5, 2, 5)\n",
    "cc, bb, _ = plt.hist(mean_R422, bins=200, range=(0,5), label='All data',\n",
    "                     color='lightgrey', density=True)\n",
    "\n",
    "plt.hist(mean_R422[interleaved_ok_selection & skyregion_selection & date_selection], bins=bb,\n",
    "         label='Runs for selected\\n source & dates',\n",
    "         density=True, histtype='step')\n",
    "\n",
    "plt.plot([min_drdi_at_422pe, min_drdi_at_422pe], \n",
    "         [0, cc.max()], '--', label='Minimum allowed', color='green')\n",
    "plt.xlabel('dR/dI cosmics rate at 422 p.e. (evts/s/p.e.)')\n",
    "plt.ylabel('number of runs (normalized)')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "fig.add_subplot(5, 2, 6)\n",
    "cc, bb, _ = plt.hist(fraction_around_mode_R422, bins=200, range=(0,1), \n",
    "                     label='All data', color='lightgrey', density=True)\n",
    "plt.hist(fraction_around_mode_R422[interleaved_ok_selection & skyregion_selection & date_selection], bins=bb,\n",
    "         label='Runs for selected\\n source & dates', density=True, histtype='step')\n",
    "\n",
    "plt.plot([min_fraction_around_mode, min_fraction_around_mode],\n",
    "         [0, cc.max()], '--', label='Minimum allowed', color='green')\n",
    "plt.xlabel('Fraction of dR/dI values around the mode for the run')\n",
    "plt.ylabel('number of runs (normalized)')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "fig.add_subplot(5, 2, 7)\n",
    "cc, bb, _ = plt.hist(mean_index, bins=200, range=(-3,0), label='All data',\n",
    "                     color='lightgrey', density=True)\n",
    "\n",
    "plt.hist(mean_index[interleaved_ok_selection & skyregion_selection & date_selection], bins=bb,\n",
    "         label='Runs for selected\\n source & dates',\n",
    "         density=True, histtype='step')\n",
    "\n",
    "plt.plot([min_drdi_index, min_drdi_index], \n",
    "         [0, cc.max()], '--', label='Minimum allowed', color='green')\n",
    "plt.plot([max_drdi_index, max_drdi_index], \n",
    "         [0, cc.max()], '--', label='Maximum allowed', color='red')\n",
    "plt.xlabel('dR/dI cosmics rate power index at 422 p.e.')\n",
    "plt.ylabel('number of runs (normalized)')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "fig.add_subplot(5, 2, 8)\n",
    "cc, bb, _ = plt.hist(np.log10(max_lsc), bins=100, range=(-6,0), label='All data',\n",
    "                     color='lightgrey', density=True)\n",
    "plt.hist(np.log10(max_lsc)[interleaved_ok_selection & skyregion_selection & date_selection], bins=bb,\n",
    "         label='Runs for selected\\n source & dates',\n",
    "         density=True, histtype='step')\n",
    "plt.plot([np.log10(max_LS_periodogram_maxamplitude), \n",
    "          np.log10(max_LS_periodogram_maxamplitude)], \n",
    "         [0, cc.max()], '--', label='Maximum allowed', color='red')\n",
    "plt.xlabel('Log10(max amplitude in LS periodogram)')\n",
    "plt.ylabel('number of runs (normalized)')\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(5, 2, 9)\n",
    "cc, _, _ = plt.hist(mean_intensity_threshold, \n",
    "                    bins=200, range=(0,200), label='All data',\n",
    "                    density=True, color='lightgrey')\n",
    "\n",
    "cc, _, _ = plt.hist(mean_intensity_threshold[interleaved_ok_selection & skyregion_selection & date_selection], \n",
    "                    bins=200, range=(0,200), label='Runs for selected\\n source & dates',\n",
    "                    density=True, histtype='step')\n",
    "plt.plot([max_intensity_at_half_peak_rate, max_intensity_at_half_peak_rate],\n",
    "         [0, cc.max()], '--', label='Maximum allowed', color='red')\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel('Intensity at 50% of dR/dI peak rate (mean during run) (p.e.)')\n",
    "plt.ylabel('number of runs (normalized)')\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(5, 2, 10)\n",
    "cc, _, _ = plt.hist(mean_intensity_at_peak_rate, \n",
    "                    bins=200, range=(0,200), label='All data', \n",
    "                    density=True, color='lightgrey')\n",
    "\n",
    "cc, _, _ = plt.hist(mean_intensity_at_peak_rate[interleaved_ok_selection & skyregion_selection & date_selection], \n",
    "                    bins=200, range=(0,200), label='Runs for selected\\n source & dates', # log=True, \n",
    "                    density=True, histtype='step')\n",
    "plt.grid()\n",
    "plt.xlabel('Intensity at dR/dI peak rate (mean during run) (p.e.)')\n",
    "plt.ylabel('number of runs (normalized)')\n",
    "plt.legend()\n",
    "\n",
    "print()\n",
    "print('The dR/dI spectrum parameters below are corrected (for each subrun) to their ZD=0 equivalent')\n",
    "print('except the intensity at the dR/dI peak rate')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nNumber of runs (% is w.r.t. those in Sky region & zenith range):\\n')\n",
    "starting_nruns = (date_selection & skyregion_selection).sum()\n",
    "print('    In the requested Sky region and range of dates:\\t', starting_nruns)\n",
    "\n",
    "nruns_within_zdrange = (date_selection & skyregion_selection & zd_selection).sum()\n",
    "print('  + zenith in requested range:\\t\\t\\t\\t', nruns_within_zdrange)\n",
    "\n",
    "nruns_nsb_ok = (date_selection & skyregion_selection & zd_selection &\n",
    "                nsb_selection).sum()\n",
    "print('  + NSB in requested range:\\t\\t\\t\\t', nruns_nsb_ok,\n",
    "      f'({nruns_nsb_ok/nruns_within_zdrange*100:.1f}%)\\n')\n",
    "\n",
    "\n",
    "nruns_interleaved_ok = (date_selection & skyregion_selection & zd_selection &\n",
    "                        nsb_selection & interleaved_ok_selection).sum()\n",
    "print('  + FF and pedestal interleaved events are present:\\t', nruns_interleaved_ok,\n",
    "      f'({nruns_interleaved_ok/nruns_within_zdrange*100:.1f}%)')\n",
    "\n",
    "nruns_stable_pointing = (date_selection & skyregion_selection & zd_selection &\n",
    "                         nsb_selection & interleaved_ok_selection & \n",
    "                         pointing_stability_selection).sum()\n",
    "print('  + Stable pointing:\\t\\t\\t\\t\\t', nruns_stable_pointing,\n",
    "      f'({nruns_stable_pointing/nruns_within_zdrange*100:.1f}%)')\n",
    "\n",
    "nruns_fit_p_value_ok = (date_selection & skyregion_selection & zd_selection &\n",
    "                        nsb_selection & interleaved_ok_selection & \n",
    "                        pointing_stability_selection &\n",
    "                        p_value_selection).sum()\n",
    "print('  + dR/dI fit P-value ok:\\t\\t\\t\\t', nruns_fit_p_value_ok,\n",
    "      f'({nruns_fit_p_value_ok/nruns_within_zdrange*100:.1f}%)')\n",
    "\n",
    "nruns_LS_periodogram_ok = (date_selection & skyregion_selection & zd_selection &\n",
    "                           nsb_selection & interleaved_ok_selection & \n",
    "                           pointing_stability_selection &\n",
    "                           p_value_selection & LS_periodogram_selection).sum()\n",
    "print('  + dR/dI LS periodogram ok:\\t\\t\\t\\t', nruns_LS_periodogram_ok,\n",
    "      f'({nruns_LS_periodogram_ok/nruns_within_zdrange*100:.1f}%)')\n",
    "\n",
    "nruns_drdi_index_ok = (date_selection & skyregion_selection & zd_selection &\n",
    "                       nsb_selection & interleaved_ok_selection & \n",
    "                       pointing_stability_selection & \n",
    "                       p_value_selection & LS_periodogram_selection &\n",
    "                       drdi_index_selection).sum()\n",
    "print('  + dR/dI index ok:\\t\\t\\t\\t\\t', nruns_drdi_index_ok,\n",
    "      f'({nruns_drdi_index_ok/nruns_within_zdrange*100:.1f}%)')\n",
    "\n",
    "nruns_drdi_rate_ok = (date_selection & skyregion_selection & zd_selection &\n",
    "                      nsb_selection & interleaved_ok_selection & \n",
    "                      pointing_stability_selection & \n",
    "                      p_value_selection & LS_periodogram_selection &\n",
    "                      drdi_index_selection & drdi_rate_selection).sum()\n",
    "\n",
    "print('  + dR/dI rate ok:\\t\\t\\t\\t\\t', nruns_drdi_rate_ok,\n",
    "      f'({nruns_drdi_rate_ok/nruns_within_zdrange*100:.1f}%)')\n",
    "\n",
    "nruns_threshold_ok = (date_selection & skyregion_selection & zd_selection &\n",
    "                      nsb_selection & interleaved_ok_selection & \n",
    "                      pointing_stability_selection & \n",
    "                      p_value_selection & LS_periodogram_selection &\n",
    "                      drdi_index_selection & drdi_rate_selection &\n",
    "                      intensity_threshold_selection).sum()\n",
    "\n",
    "print('  + intensity threshold ok:\\t\\t\\t\\t', nruns_threshold_ok,\n",
    "      f'({nruns_threshold_ok/nruns_within_zdrange*100:.1f}%)')\n",
    "\n",
    "print('\\nNote: about 64% of all *dark-night* observations within ZD<80 deg fulfill all quality cuts.')\n",
    "print('(in the stable, good-quality period 20221118 - 20230214, 92% of *dark-night* observations within ZD<80 deg do).')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_no_drdi_rate_cut = (date_selection & \n",
    "                         skyregion_selection & \n",
    "                         zd_selection & \n",
    "                         nsb_selection &\n",
    "                         interleaved_ok_selection & \n",
    "                         pointing_stability_selection & \n",
    "                         p_value_selection &\n",
    "                         LS_periodogram_selection &\n",
    "                         drdi_index_selection &\n",
    "                         intensity_threshold_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = mask_no_drdi_rate_cut & drdi_rate_selection\n",
    "\n",
    "good_runs = runlist[mask]\n",
    "\n",
    "print('Selected:', mask.sum(), 'of', runlist.size, 'runs')\n",
    "\n",
    "obs_hours = runsummary['elapsed_time'][mask].sum()/3600\n",
    "\n",
    "print(f'Total observation time: {obs_hours:.2f} h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a mask of selected data which works for the subrun-wise table:\n",
    "subrun_mask = np.array([True if x in good_runs else False for x in cis['runnumber']])\n",
    "subrun_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_dates = np.unique(rundate[mask])\n",
    "\n",
    "print()\n",
    "print('Total number of runs:', good_runs.size, '(in', good_dates.size ,'nights)')\n",
    "obs_hours = runsummary['elapsed_time'][mask].sum()/3600\n",
    "print(f'Total observation time: {obs_hours:.2f} hours')\n",
    "print()\n",
    "\n",
    "dates_runs_dict = {}\n",
    "dates = []\n",
    "\n",
    "for dd in good_dates:\n",
    "    print(dd)\n",
    "    dates.append(dd)\n",
    "    print('--------')\n",
    "    print('  ', runlist[mask & (rundate==dd)])\n",
    "    dates_runs_dict[dd] = runlist[mask & (rundate==dd)]\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/Users/vdk/muons2024/data_quality_winter_2024/dates_runs_dict.pkl', 'wb') as file:\n",
    "    # Step 4: Serialize and save the dictionary\n",
    "    pickle.dump(dates_runs_dict, file)\n",
    "\n",
    "print(\"Dictionary has been pickled and saved to 'dates_runs_dict.pkl'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '/fefs/aswg/data/real/DL1/{date}/v0.10/muons/muons_LST-1.Run{runnumber}.fits'\n",
    "\n",
    "for key, value in dates_runs_dict.items():\n",
    "    for runnumber in value:\n",
    "        print(template.format(date=key, runnumber=runnumber))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/vdk/muons2024/data_quality_winter_2024/dates_runs_dict.pkl', 'rb') as file:\n",
    "    loaded_dates_runs_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_paths = []\n",
    "\n",
    "for key, value in loaded_dates_runs_dict.items():\n",
    "    for runnumber in value:\n",
    "        print(template.format(date=key, runnumber=runnumber))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((runsummary_pd['elapsed_time']/60), bins = 40, histtype='step', density = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_runs = runsummary_pd['runnumber'][((runsummary_pd['elapsed_time']/60) > 18) & ((runsummary_pd['elapsed_time']/60) < 22)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(long_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_nsb_runs_2024 = cis_pd[['yyyymmdd','runnumber', 'subrun']][(cis_pd['diffuse_nsb_std'] < max_diffuse_nsb_std)]\n",
    "low_nsb_runs_2024_full = cis_pd[(cis_pd['diffuse_nsb_std'] < max_diffuse_nsb_std)]\n",
    "low_nsb_runsummary_2024  = runsummary_pd[runsummary_pd['runnumber'].isin(low_nsb_runs_2024['runnumber'])]\n",
    "len(low_nsb_runsummary_2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_runs = low_nsb_runsummary_2024['runnumber'][((low_nsb_runsummary_2024['elapsed_time']/60) > 18) & ((low_nsb_runsummary_2024['elapsed_time']/60) < 22)]\n",
    "long_runs_full = low_nsb_runsummary_2024[((low_nsb_runsummary_2024['elapsed_time']/60) > 18) & ((low_nsb_runsummary_2024['elapsed_time']/60) < 22)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(long_runs)/len(low_nsb_runsummary_2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pd = cis_pd[(cis_pd['diffuse_nsb_std'] < max_diffuse_nsb_std)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(low_nsb_runs_2024_full['diffuse_nsb_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Series to a CSV file\n",
    "#long_runs.to_csv('/Users/vdk/Software/code/muon_paper_2024/series_data.csv')  # header=True to include the index name if it has one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file back into a DataFrame\n",
    "data_loaded = pd.read_csv('/Users/vdk/Software/code/muon_paper_2024/series_data.csv', index_col=0)\n",
    "\n",
    "# Print the Series to verify\n",
    "# print(data_loaded)\n",
    "\n",
    "# Iterate through the Series and print each value\n",
    "for index, value in data_loaded.items():\n",
    "    print(f\"{(value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array(data_loaded).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten_test = test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('/Users/vdk/muons2024/v0.9-v0.10/20*/DL1_datacheck_*.h5')\n",
    "files.sort()\n",
    "\n",
    "runsummary = []\n",
    "cosmics = []\n",
    "cis = []\n",
    "for file in files:\n",
    "    try:\n",
    "        runsummary.append(pd.read_hdf(file, 'runsummary'))\n",
    "        cosmics.append(pd.read_hdf(file, 'cosmics'))\n",
    "        cis.append(pd.read_hdf(file, 'cosmics_intensity_spectrum'))\n",
    "    except:\n",
    "        print(file)\n",
    "    \n",
    "cosmics_pd = pd.concat(cosmics, ignore_index=True)\n",
    "runsummary_pd = pd.concat(runsummary, ignore_index=True)\n",
    "cis_pd = pd.concat(cis, ignore_index=True)\n",
    "cosmics_pd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(list(cosmics_pd['elapsed_time']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cis_pd['diffuse_nsb_std'][(cis_pd['runnumber']==16893)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runsummary_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_nsb_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose only runsummary for low_nsb runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_nsb_runs = cis_pd[['yyyymmdd','runnumber', 'subrun']][(cis_pd['diffuse_nsb_std'] < max_diffuse_nsb_std)]\n",
    "low_nsb_runsummary = runsummary_pd[runsummary_pd['runnumber'].isin(low_nsb_runs['runnumber'])]\n",
    "low_nsb_cosmics = cosmics_pd[cosmics_pd['runnumber'].isin(low_nsb_runs['runnumber'])]\n",
    "low_nsb_cosmics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_low_nsb = pd.DataFrame(set(low_nsb_cosmics['runnumber'][(low_nsb_cosmics['time'] > 1709158619.7528722)]), columns=['runnumber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low nsb runs for 2024 year, after February\n",
    "set_low_nsb.to_csv('/Users/vdk/Software/code/muon_paper_2024/low_nsb_2024year.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_low_nsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_nsb_runs = cis_pd[['yyyymmdd','runnumber', 'subrun']][(cis_pd['diffuse_nsb_std'] > max_diffuse_nsb_std)]\n",
    "high_nsb_runsummary = runsummary_pd[runsummary_pd['runnumber'].isin(high_nsb_runs['runnumber'])]\n",
    "high_nsb_cosmics = cosmics_pd[cosmics_pd['runnumber'].isin(high_nsb_runs['runnumber'])]\n",
    "high_nsb_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_nsb_high_murings_rungs = runsummary_pd['runnumber'][runsummary_pd['num_contained_mu_rings'] > 2000]\n",
    "type(high_nsb_high_murings_rungs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = high_nsb_runs[high_nsb_runs['runnumber'].isin(high_nsb_high_murings_rungs)]\n",
    "intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection[intersection['runnumber'] == 16867]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searched_row = cis_pd.loc[(cis_pd['runnumber'] == 16876) & (cis_pd['subrun'] == 54)]\n",
    "searched_row['diffuse_nsb_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cis_pd['runnumber'][cis_pd['runnumber'] == 16876]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#high_nsb_runs.to_csv('/Users/vdk/highNSBvalues.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unix timestamp\n",
    "timestamp = 1.605927e+09\n",
    "\n",
    "# Convert to a datetime object\n",
    "dt_object = datetime.fromtimestamp(timestamp)\n",
    "\n",
    "# Print the datetime in a human-readable format\n",
    "print(dt_object.strftime('%Y-%m-%d %H:%M:%S'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mueff2019 = low_nsb_runsummary['mu_effi_mean'][(low_nsb_runsummary['time'] > start_date_2019) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2019)]\n",
    "mueff2020 = low_nsb_runsummary['mu_effi_mean'][(low_nsb_runsummary['time'] > start_date_2020) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2020)]\n",
    "mueff2021 = low_nsb_runsummary['mu_effi_mean'][(low_nsb_runsummary['time'] > start_date_2021) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2021)]\n",
    "mueff2022 = low_nsb_runsummary['mu_effi_mean'][(low_nsb_runsummary['time'] > start_date_2022) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2022)]\n",
    "mueff2023 = low_nsb_runsummary['mu_effi_mean'][(low_nsb_runsummary['time'] > start_date_2023) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2023)]\n",
    "mueff2024 = low_nsb_runsummary['mu_effi_mean'][(low_nsb_runsummary['time'] > start_date_2024) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2024)]\n",
    "\n",
    "mustd2019 = low_nsb_runsummary['mu_effi_stddev'][(low_nsb_runsummary['time'] > start_date_2019) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2019)]\n",
    "mustd2020 = low_nsb_runsummary['mu_effi_stddev'][(low_nsb_runsummary['time'] > start_date_2020) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2020)]\n",
    "mustd2021 = low_nsb_runsummary['mu_effi_stddev'][(low_nsb_runsummary['time'] > start_date_2021) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2021)]\n",
    "mustd2022 = low_nsb_runsummary['mu_effi_stddev'][(low_nsb_runsummary['time'] > start_date_2022) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2022)]\n",
    "mustd2023 = low_nsb_runsummary['mu_effi_stddev'][(low_nsb_runsummary['time'] > start_date_2023) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2023)]\n",
    "mustd2024 = low_nsb_runsummary['mu_effi_stddev'][(low_nsb_runsummary['time'] > start_date_2024) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2024)]\n",
    "\n",
    "musize2019 = low_nsb_runsummary['mu_intensity_mean'][(low_nsb_runsummary['time'] > start_date_2019) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2019)]\n",
    "musize2020 = low_nsb_runsummary['mu_intensity_mean'][(low_nsb_runsummary['time'] > start_date_2020) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2020)]\n",
    "musize2021 = low_nsb_runsummary['mu_intensity_mean'][(low_nsb_runsummary['time'] > start_date_2021) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2021)]\n",
    "musize2022 = low_nsb_runsummary['mu_intensity_mean'][(low_nsb_runsummary['time'] > start_date_2022) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2022)]\n",
    "musize2023 = low_nsb_runsummary['mu_intensity_mean'][(low_nsb_runsummary['time'] > start_date_2023) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2023)]\n",
    "musize2024 = low_nsb_runsummary['mu_intensity_mean'][(low_nsb_runsummary['time'] > start_date_2024) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2024)]\n",
    "\n",
    "print(f\"Mean opt eff for 2019 year = {np.mean(mueff2019)} with std = {np.mean(mustd2019)}\")\n",
    "print(f\"Mean opt eff for 2020 year = {np.mean(mueff2020)} with std = {np.mean(mustd2020)}\")\n",
    "print(f\"Mean opt eff for 2021 year = {np.mean(mueff2021)} with std = {np.mean(mustd2021)}\")\n",
    "print(f\"Mean opt eff for 2022 year = {np.mean(mueff2022)} with std = {np.mean(mustd2022)}\")\n",
    "print(f\"Mean opt eff for 2023 year = {np.mean(mueff2023)} with std = {np.mean(mustd2023)}\")\n",
    "print(f\"Mean opt eff for 2024 year = {np.mean(mueff2024)} with std = {np.mean(mustd2024)}\")\n",
    "\n",
    "print(f\"Mean ring size for 2019 year = {np.mean(musize2019)}\")\n",
    "print(f\"Mean ring size for 2020 year = {np.mean(musize2020)}\")\n",
    "print(f\"Mean ring size for 2021 year = {np.mean(musize2021)}\")\n",
    "print(f\"Mean ring size for 2022 year = {np.mean(musize2022)}\")\n",
    "print(f\"Mean ring size for 2023 year = {np.mean(musize2023)}\")\n",
    "print(f\"Mean ring size for 2024 year = {np.mean(musize2024)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mueff2019 = high_nsb_runsummary['mu_effi_mean'][(high_nsb_runsummary['time'] > start_date_2019) &\n",
    "                                           (high_nsb_runsummary['time'] < end_date_2019)]\n",
    "mueff2020 = high_nsb_runsummary['mu_effi_mean'][(high_nsb_runsummary['time'] > start_date_2020) &\n",
    "                                           (high_nsb_runsummary['time'] < end_date_2020)]\n",
    "mueff2021 = high_nsb_runsummary['mu_effi_mean'][(high_nsb_runsummary['time'] > start_date_2021) &\n",
    "                                           (high_nsb_runsummary['time'] < end_date_2021)]\n",
    "mueff2022 = high_nsb_runsummary['mu_effi_mean'][(high_nsb_runsummary['time'] > start_date_2022) &\n",
    "                                           (high_nsb_runsummary['time'] < end_date_2022)]\n",
    "mueff2023 = high_nsb_runsummary['mu_effi_mean'][(high_nsb_runsummary['time'] > start_date_2023) &\n",
    "                                           (high_nsb_runsummary['time'] < end_date_2023)]\n",
    "mueff2024 = high_nsb_runsummary['mu_effi_mean'][(high_nsb_runsummary['time'] > start_date_2024) &\n",
    "                                           (high_nsb_runsummary['time'] < end_date_2024)]\n",
    "\n",
    "mustd2019 = low_nsb_runsummary['mu_effi_stddev'][(low_nsb_runsummary['time'] > start_date_2019) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2019)]\n",
    "mustd2020 = low_nsb_runsummary['mu_effi_stddev'][(low_nsb_runsummary['time'] > start_date_2020) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2020)]\n",
    "mustd2021 = low_nsb_runsummary['mu_effi_stddev'][(low_nsb_runsummary['time'] > start_date_2021) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2021)]\n",
    "mustd2022 = low_nsb_runsummary['mu_effi_stddev'][(low_nsb_runsummary['time'] > start_date_2022) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2022)]\n",
    "mustd2023 = low_nsb_runsummary['mu_effi_stddev'][(low_nsb_runsummary['time'] > start_date_2023) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2023)]\n",
    "mustd2024 = low_nsb_runsummary['mu_effi_stddev'][(low_nsb_runsummary['time'] > start_date_2024) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2024)]\n",
    "\n",
    "musize2019 = high_nsb_runsummary['mu_intensity_mean'][(high_nsb_runsummary['time'] > start_date_2019) &\n",
    "                                           (high_nsb_runsummary['time'] < end_date_2019)]\n",
    "musize2020 = high_nsb_runsummary['mu_intensity_mean'][(high_nsb_runsummary['time'] > start_date_2020) &\n",
    "                                           (high_nsb_runsummary['time'] < end_date_2020)]\n",
    "musize2021 = high_nsb_runsummary['mu_intensity_mean'][(high_nsb_runsummary['time'] > start_date_2021) &\n",
    "                                           (high_nsb_runsummary['time'] < end_date_2021)]\n",
    "musize2022 = high_nsb_runsummary['mu_intensity_mean'][(high_nsb_runsummary['time'] > start_date_2022) &\n",
    "                                           (high_nsb_runsummary['time'] < end_date_2022)]\n",
    "musize2023 = high_nsb_runsummary['mu_intensity_mean'][(high_nsb_runsummary['time'] > start_date_2023) &\n",
    "                                           (high_nsb_runsummary['time'] < end_date_2023)]\n",
    "musize2024 = high_nsb_runsummary['mu_intensity_mean'][(high_nsb_runsummary['time'] > start_date_2024) &\n",
    "                                           (high_nsb_runsummary['time'] < end_date_2024)]\n",
    "\n",
    "print(f\"Mean opt eff for 2019 year = {np.mean(mueff2019)} with std = {np.mean(mustd2019)}\")\n",
    "print(f\"Mean opt eff for 2020 year = {np.mean(mueff2020)} with std = {np.mean(mustd2020)}\")\n",
    "print(f\"Mean opt eff for 2021 year = {np.mean(mueff2021)} with std = {np.mean(mustd2021)}\")\n",
    "print(f\"Mean opt eff for 2022 year = {np.mean(mueff2022)} with std = {np.mean(mustd2022)}\")\n",
    "print(f\"Mean opt eff for 2023 year = {np.mean(mueff2023)} with std = {np.mean(mustd2023)}\")\n",
    "print(f\"Mean opt eff for 2024 year = {np.mean(mueff2024)} with std = {np.mean(mustd2024)}\")\n",
    "\n",
    "print(f\"Mean ring size for 2019 year = {np.mean(musize2019)}\")\n",
    "print(f\"Mean ring size for 2020 year = {np.mean(musize2020)}\")\n",
    "print(f\"Mean ring size for 2021 year = {np.mean(musize2021)}\")\n",
    "print(f\"Mean ring size for 2022 year = {np.mean(musize2022)}\")\n",
    "print(f\"Mean ring size for 2023 year = {np.mean(musize2023)}\")\n",
    "print(f\"Mean ring size for 2024 year = {np.mean(musize2024)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs2019 = low_nsb_runsummary['runnumber'][(low_nsb_runsummary['time'] > start_date_2019) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2019)]\n",
    "runs2020 = low_nsb_runsummary['runnumber'][(low_nsb_runsummary['time'] > start_date_2020) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2020)]\n",
    "runs2021 = low_nsb_runsummary['runnumber'][(low_nsb_runsummary['time'] > start_date_2021) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2021)]\n",
    "runs2022 = low_nsb_runsummary['runnumber'][(low_nsb_runsummary['time'] > start_date_2022) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2022)]\n",
    "runs2023 = low_nsb_runsummary['runnumber'][(low_nsb_runsummary['time'] > start_date_2023) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2023)]\n",
    "runs2024 = low_nsb_runsummary['runnumber'][(low_nsb_runsummary['time'] > start_date_2024) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2024)]\n",
    "\n",
    "mueff2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(low_nsb_runsummary['mu_effi_mean'][-500:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(low_nsb_runsummary['mu_effi_mean'][:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytext = 600\n",
    "plt.figure(figsize = (12,9))\n",
    "sns.regplot(x=low_nsb_runsummary['runnumber'], y=low_nsb_runsummary['mu_intensity_mean'], color='k', scatter_kws={'s': 10})#, x_bins = 400)\n",
    "sns.regplot(x=high_nsb_runsummary['runnumber'], y=high_nsb_runsummary['mu_intensity_mean'], color='r', scatter_kws={'s': 10})#, x_bins = 400)\n",
    "sns.regplot(x=runsummary_pd['runnumber'], y=runsummary_pd['mu_intensity_mean'], color='g', scatter_kws={'s': 10})#, x_bins = 400)\n",
    "plt.fill_betweenx(y=[0,4000], x1 = 0, x2=max(runs2019), alpha = 0.05)\n",
    "plt.fill_betweenx(y=[0,4000], x1 = max(runs2019), x2=max(runs2020), alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,4000], x1 = max(runs2020), x2=max(runs2021), alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,4000], x1 = max(runs2021), x2=max(runs2022), alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,4000], x1 = max(runs2022), x2=max(runs2023), alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,4000], x1 = max(runs2023), x2=20000, alpha = 0.075)\n",
    "plt.annotate(\"2019\",(600,250), c='red')\n",
    "plt.annotate(\"2020\",(2200,ytext), c='red')\n",
    "plt.annotate(\"2021\",(4500,ytext), c='red')\n",
    "plt.annotate(\"2022\",(8500,ytext), c='red')\n",
    "plt.annotate(\"2023\",(13700, ytext), c='red')\n",
    "plt.annotate(\"2024\",(16600,ytext), c='red')\n",
    "plt.ylim(500,3500)\n",
    "plt.xlim(0,17500)\n",
    "plt.grid(alpha = 0.2)\n",
    "plt.xlabel('Runnumber')\n",
    "plt.ylabel('Size of the muon ring [p.e.]')\n",
    "#plt.savefig('/Users/vdk/muons2024/images/prague_talk/mu_size.png', dpi=200, format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytext = 0.01\n",
    "plt.figure(figsize = (12,9))\n",
    "sns.regplot(x=low_nsb_runsummary['runnumber'], y=low_nsb_runsummary['mu_width_mean'], color='k', scatter_kws={'s': 10}, x_bins = 100)\n",
    "sns.regplot(x=high_nsb_runsummary['runnumber'], y=high_nsb_runsummary['mu_width_mean'], color='r', scatter_kws={'s': 10}, x_bins = 100)\n",
    "sns.regplot(x=runsummary_pd['runnumber'], y=runsummary_pd['mu_width_mean'], color='g', scatter_kws={'s': 10}, x_bins = 100)\n",
    "plt.fill_betweenx(y=[0,4000], x1 = 0, x2=max(runs2019), alpha = 0.05)\n",
    "plt.fill_betweenx(y=[0,4000], x1 = max(runs2019), x2=max(runs2020), alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,4000], x1 = max(runs2020), x2=max(runs2021), alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,4000], x1 = max(runs2021), x2=max(runs2022), alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,4000], x1 = max(runs2022), x2=max(runs2023), alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,4000], x1 = max(runs2023), x2=20000, alpha = 0.075)\n",
    "plt.annotate(\"2019\",(600, ytext), c='red')\n",
    "plt.annotate(\"2020\",(2200,ytext), c='red')\n",
    "plt.annotate(\"2021\",(4500,ytext), c='red')\n",
    "plt.annotate(\"2022\",(8500,ytext), c='red')\n",
    "plt.annotate(\"2023\",(13700, ytext), c='red')\n",
    "plt.annotate(\"2024\",(16600,ytext), c='red')\n",
    "plt.ylim(0,0.125)\n",
    "plt.xlim(0,17500)\n",
    "plt.grid(alpha = 0.2)\n",
    "plt.xlabel('Runnumber')\n",
    "plt.ylabel('Width of the ring [deg]')\n",
    "#plt.savefig('/Users/vdk/muons2024/images/prague_talk/mu_width.png', dpi=200, format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muwidth2020 = low_nsb_runsummary['mu_width_mean'][(low_nsb_runsummary['time'] > start_date_2020) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2020)]\n",
    "muwidth2023 = low_nsb_runsummary['mu_width_mean'][(low_nsb_runsummary['time'] > start_date_2023) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2023)]\n",
    "muwidth2024 = low_nsb_runsummary['mu_width_mean'][(low_nsb_runsummary['time'] > start_date_2024) &\n",
    "                                           (low_nsb_runsummary['time'] < end_date_2024)]\n",
    "\n",
    "print(f\"Mean ring width for 2020 year = {np.mean(muwidth2020)}\")\n",
    "print(f\"Mean ring width for 2023 year = {np.mean(muwidth2023)}\")\n",
    "print(f\"Mean ring width for 2024 year = {np.mean(muwidth2024)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.06812494859062546/0.07033345270082957"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytext = 0.92\n",
    "plt.figure(figsize = (12,9))\n",
    "sns.regplot(x=low_nsb_cosmics['runnumber'], y=low_nsb_cosmics['mu_radius_mean'], color='k', scatter_kws={'s': 10}, x_bins = 600)#x_bins = int(len(low_nsb_cosmics['runnumber'])**0.5))\n",
    "plt.fill_betweenx(y=[0,4000], x1 = 0, x2=max(runs2019), alpha = 0.05)\n",
    "plt.fill_betweenx(y=[0,4000], x1 = max(runs2019), x2=max(runs2020), alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,4000], x1 = max(runs2020), x2=max(runs2021), alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,4000], x1 = max(runs2021), x2=max(runs2022), alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,4000], x1 = max(runs2022), x2=max(runs2023), alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,4000], x1 = max(runs2023), x2=20000, alpha = 0.075)\n",
    "plt.annotate(\"2019\",(600, ytext), c='red')\n",
    "plt.annotate(\"2020\",(2200,ytext), c='red')\n",
    "plt.annotate(\"2021\",(4500,ytext), c='red')\n",
    "plt.annotate(\"2022\",(8500,ytext), c='red')\n",
    "plt.annotate(\"2023\",(13700, ytext), c='red')\n",
    "plt.annotate(\"2024\",(16600,ytext), c='red')\n",
    "plt.ylim(0.9,1.3)\n",
    "plt.xlim(0,17500)\n",
    "plt.grid(alpha = 0.2)\n",
    "plt.xlabel('Runnumber')\n",
    "plt.ylabel('Radius of the ring [deg]')\n",
    "#plt.savefig('/Users/vdk/muons2024/images/prague_talk/mu_radius.png', dpi=200, format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_nsb_cosmics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_nsb_cosmics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = '/Users/vdk/dl1_run201_muon_lst.h5'\n",
    "with h5py.File(test_file, 'r') as file:\n",
    "    # List all groups and datasets in the file\n",
    "    print(\"Contents of the HDF5 file:\")\n",
    "    for name in file:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with pd.HDFStore(test_file) as hdf:\n",
    "    print(hdf.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('/Users/vdk/muons2024/v0.9-v0.10/20*/DL1_datacheck_*.h5')\n",
    "files.sort()\n",
    "\n",
    "# This takes a few minutes... DON'T RUN IT MORE THAN ONCE, it is not needed! (If you change the \n",
    "# sky region or the cuts just execute the cells from \"Data selection configuration\" onwards)\n",
    "dummy = []\n",
    "dummy2 = []\n",
    "dummy3 = []\n",
    "\n",
    "missing_flatfield_tables = 0\n",
    "for i, file in enumerate(files):\n",
    "    if i%10 == 0:\n",
    "        print(i, '/', len(files), file)\n",
    "    try:\n",
    "        dummy.append(pd.read_hdf(file, 'cosmics_intensity_spectrum'))\n",
    "        dummy2.append(pd.read_hdf(file, 'runsummary'))\n",
    "        fftable = pd.read_hdf(file, 'flatfield', errors='ignore')\n",
    "        dummy3.append(fftable)\n",
    "    except: \n",
    "            # some check files have no flatfield table at all (if calibox was off) \n",
    "        missing_flatfield_tables += 1\n",
    "\n",
    "# cosmics intensity spectra table (subrun-wise):\n",
    "cis = pd.concat(dummy, ignore_index=True)\n",
    "\n",
    "# flatfield table (subrun-wise):\n",
    "flatfield = pd.concat(dummy3, ignore_index=True)\n",
    "\n",
    "# parameters computed run-wise:\n",
    "runsummary = pd.concat(dummy2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cis.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runsummary.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runsummary['time'] + runsummary['elapsed_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muon_file = '/Users/vdk/muons2024/fits_complete_rings_low_nsb.csv'\n",
    "complete_muons = pd.read_csv(muon_file, na_values=['NA', '?'])\n",
    "complete_muons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_muons['event_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z,x,c = plt.hist(cis['cos_zenith'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose only runs with zenith anlge < 5 degrees and then create two tables with the time of start and time of end\n",
    "runnumbers = cis['runnumber'][cis['cos_zenith'] >= np.cos(np.deg2rad(5))]\n",
    "zenith_table = runsummary[runsummary['runnumber'].isin(runnumbers)]\n",
    "start_table = zenith_table['time']\n",
    "end_table = zenith_table['time']+zenith_table['elapsed_time']\n",
    "# for index,row in new_table.iterrow:\n",
    "#     print(row)\n",
    "for start, end in zip(start_table, end_table):\n",
    "    print(f\"start = {start} / end = {end} and difference = {start - end}\")\n",
    "\n",
    "zenith_table.to_csv('/Users/vdk/muons2024/data_zenith_cuts/zenith<5deg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(np.rad2deg(runsummary['mean_altitude']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runsummary.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runsummary['runnumber'][(np.degrees(runsummary['mean_altitude']) > 88) & (np.degrees(runsummary['mean_altitude']) < 90)] #& (runsummary_pd['mu_radius_mean'] > 0.95) & (runsummary_pd['mu_radius_mean'] < 1.3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets choose only values with zenith anlge that differs not much than 1 degree\n",
    "def delta(a,b):\n",
    "    return abs(np.rad2deg(a)-np.rad2deg(b))\n",
    "\n",
    "#runsummary_pd['runnumber'][(np.degrees(runsummary_pd['_altitude']) > 44) & (np.degrees(runsummary_pd['mean_altitude']) < 45)]) #& (runsummary_pd['mu_radius_mean'] > 0.95) & (runsummary_pd['mu_radius_mean'] < 1.3)]\n",
    "zd_runnumbers = runsummary_pd['runnumber'][\n",
    "    (delta(runsummary_pd['min_altitude'],runsummary_pd['max_altitude'])< 1) & \n",
    "    (delta(runsummary_pd['min_azimuth'],runsummary_pd['max_azimuth'])< 1) & \n",
    "    (runsummary_pd['mu_effi_stddev']<=0.02) & \n",
    "    (runsummary_pd['mu_width_stddev']<0.02) &\n",
    "    (runsummary_pd['num_contained_mu_rings'])\n",
    "]\n",
    "zenith_table = runsummary_pd[runsummary_pd['runnumber'].isin(zd_runnumbers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table = cis[['yyyymmdd','runnumber', 'subrun']][(cis['diffuse_nsb_std'] < max_diffuse_nsb_std)]\n",
    "new_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_table.to_csv('/Users/vdk/muons2024/1000-2000BigFitsLSTcuts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runsummary_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_opt_efficiency = []\n",
    "observation_date = []\n",
    "mean_runs = []\n",
    "std_opt = []\n",
    "mean_width = []\n",
    "mean_width_std = []\n",
    "mean_size = []\n",
    "mean_radius = []\n",
    "radius = []\n",
    "width = []\n",
    "\n",
    "\n",
    "for observation in cosmics:\n",
    "    print(observation)\n",
    "    time = np.mean(observation['time']) \n",
    "    observation_date.append(datetime.utcfromtimestamp(time).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    mean_opt_efficiency.append(np.mean(observation['mu_effi_mean']))\n",
    "    mean_runs.append(int(np.mean(observation['runnumber'])))\n",
    "    std_opt.append(np.mean(observation['mu_effi_stddev']))\n",
    "    mean_width.append(np.mean(observation['mu_width_mean']))\n",
    "    mean_width_std.append(np.mean(observation['mu_width_stddev']))\n",
    "    mean_size.append(np.mean(observation['mu_intensity_mean']))\n",
    "    mean_radius.append(np.mean(observation['mu_radius_mean']))\n",
    "    for radi in observation['mu_radius_mean']:\n",
    "        radius.append(radi)\n",
    "    for wid in observation['mu_width_mean']:\n",
    "        width.append(wid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoprithm to count number of runs in each year\n",
    "\n",
    "time = []\n",
    "runnumber = []\n",
    "\n",
    "for observ in runsummary:\n",
    "    for item in observ['time']:\n",
    "        time.append(item)\n",
    "\n",
    "\n",
    "time = [datetime.utcfromtimestamp(item).strftime('%Y-%m-%d %H:%M:%S') for item in time]\n",
    "dates = []\n",
    "for date in time:\n",
    "    dates.append(int(date.split(' ')[0][:4]))\n",
    "\n",
    "check_points = []\n",
    "check = 0  \n",
    "for year in set(dates):\n",
    "    check_points.append(dates.count(year)+check)\n",
    "    check = check + dates.count(year)\n",
    "\n",
    "runs = []\n",
    "runs_check = 0  \n",
    "for i,observ in enumerate(runsummary):\n",
    "    for run in observ['runnumber']:\n",
    "        runs.append(run)\n",
    " \n",
    "x_fill = [runsummary[0]['runnumber'][0]]\n",
    "for i,run in enumerate(runs):\n",
    "    if i in check_points:\n",
    "        x_fill.append(run)\n",
    "        \n",
    "x_fill.append(runsummary[-1]['runnumber'][9])\n",
    "\n",
    "print(f\"number of runs in each year {x_fill}\")\n",
    "print(f\"2019 year = {dates.count(2019)}\")\n",
    "print(f\"2020 year = {dates.count(2020)}\")\n",
    "print(f\"2021 year = {dates.count(2021)}\")\n",
    "print(f\"2022 year = {dates.count(2022)}\")\n",
    "print(f\"2023 year = {dates.count(2023)}\")\n",
    "print(f\"2024 year = {dates.count(2024)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,9))\n",
    "sns.regplot(x = mean_runs, y = mean_opt_efficiency, color = 'k')#, label = 'Mean Optical Efficiency during one observation')#, x_bins=75\n",
    "#plt.errorbar(mean_runs, mean_opt_efficiency, yerr=std_opt, fmt = 'none', capsize=5, zorder=1, color='C0', alpha = 0.4)\n",
    "plt.grid(alpha = 0.3)\n",
    "plt.title(\"Optical Efficiency for all LST1 observational time\")\n",
    "#plt.vlines(3000,0,0.3)\n",
    "plt.ylim(0.1,0.275)\n",
    "plt.fill_betweenx(y=[0,0.3], x1 = 0, x2=x_fill[1], alpha = 0.05)\n",
    "plt.fill_betweenx(y=[0,0.3], x1 = x_fill[1], x2=x_fill[2], alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,0.3], x1 = x_fill[2], x2=x_fill[3], alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,0.3], x1 = x_fill[3], x2=x_fill[4], alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,0.3], x1 = x_fill[4], x2=x_fill[5], alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,0.3], x1 = x_fill[5], x2=18000, alpha = 0.075)\n",
    "plt.xlim(0,18000)\n",
    "plt.xlabel('Run number')\n",
    "plt.ylabel('Mean optical efficiency')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_value_str = 'runnumber'\n",
    "y_value_str = 'mu_effi_mean'\n",
    "df_good_data = cosmics_pd\n",
    "# Step 1: Create bins for 'ring_radius'\n",
    "df_good_data[f'{x_value_str}_bin'] = pd.cut(df_good_data[x_value_str], bins=100)\n",
    "\n",
    "# Step 2: Group by the new bin column and calculate mean 'ring_size' for each bin\n",
    "binned_data = df_good_data.groupby(f'{x_value_str}_bin')[y_value_str].mean().reset_index()\n",
    "\n",
    "# Step 3: Convert the bin intervals to strings (for plotting) or use midpoints\n",
    "binned_data['bin_mid'] = binned_data[f'{x_value_str}_bin'].apply(lambda x: x.mid)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot of binned values\n",
    "plt.scatter(binned_data['bin_mid'], binned_data[y_value_str], label='Binned Muon Efficiency', s=20)\n",
    "\n",
    "# Calculate and plot the regression line over the original data\n",
    "m, b = np.polyfit(df_good_data[x_value_str], df_good_data[y_value_str], 1)\n",
    "plt.plot(df_good_data[x_value_str], m*df_good_data[x_value_str] + b, color='red', label='Regression Line', alpha = 0.75)\n",
    "\n",
    "plt.xlabel(f'{x_value_str}')\n",
    "plt.ylabel(f'{y_value_str}')\n",
    "#plt.axhline(y=mean_ring_size, color='g', linestyle='--', label = f'Mean ring_size for this period = {round(mean_ring_size, 3)}')\n",
    "#plt.axvline(x=mean_ring_radius, color='orange', linestyle='--', label = f'Mean ring radius for this period = {round(mean_ring_radius,3)} pe')\n",
    "plt.legend()\n",
    "#plt.ylim(0,1.1)\n",
    "#plt.xlim(0,0.3)\n",
    "plt.grid(alpha=0.5)\n",
    "#plt.show()\n",
    "#plt.savefig('/home/jovyan/XImpact.png', dpi=300, format='png', bbox_inches='tight')\n",
    "#plt.savefig('/home/jovyan/OptEffVSImpact.png', dpi=300, format='png', bbox_inches='tight')\n",
    "#plt.savefig('/Users/vdk/muons2024/images/RadiusVsSize_19-23Y.png', dpi=200, format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_value_str = 'runnumber'\n",
    "y_value_str = 'mu_effi_mean'\n",
    "df_good_data = cosmics_pd\n",
    "# Step 1: Create bins for 'ring_radius'\n",
    "df_good_data[f'{x_value_str}_bin'] = pd.cut(df_good_data[x_value_str], bins=100)\n",
    "\n",
    "# Step 2: Group by the new bin column and calculate mean 'ring_size' for each bin\n",
    "binned_data = df_good_data.groupby(f'{x_value_str}_bin')[y_value_str].mean().reset_index()\n",
    "\n",
    "# Step 3: Convert the bin intervals to strings (for plotting) or use midpoints\n",
    "binned_data['bin_mid'] = binned_data[f'{x_value_str}_bin'].apply(lambda x: x.mid)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot of binned values\n",
    "plt.scatter(binned_data['bin_mid'], binned_data[y_value_str], label='Binned Muon Efficiency', s=20)\n",
    "\n",
    "# Calculate and plot the regression line over the original data\n",
    "m, b = np.polyfit(df_good_data[x_value_str], df_good_data[y_value_str], 1)\n",
    "plt.plot(df_good_data[x_value_str], m*df_good_data[x_value_str] + b, color='red', label='Regression Line', alpha = 0.75)\n",
    "\n",
    "plt.xlabel(f'{x_value_str}')\n",
    "plt.ylabel(f'{y_value_str}')\n",
    "#plt.axhline(y=mean_ring_size, color='g', linestyle='--', label = f'Mean ring_size for this period = {round(mean_ring_size, 3)}')\n",
    "#plt.axvline(x=mean_ring_radius, color='orange', linestyle='--', label = f'Mean ring radius for this period = {round(mean_ring_radius,3)} pe')\n",
    "plt.legend()\n",
    "#plt.ylim(0,2)\n",
    "#plt.xlim(0,0.3)\n",
    "plt.grid(alpha=0.5)\n",
    "#plt.show()\n",
    "#plt.savefig('/home/jovyan/XImpact.png', dpi=300, format='png', bbox_inches='tight')\n",
    "#plt.savefig('/home/jovyan/OptEffVSImpact.png', dpi=300, format='png', bbox_inches='tight')\n",
    "#plt.savefig('/Users/vdk/muons2024/images/RadiusVsSize_19-23Y.png', dpi=200, format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,9))\n",
    "sns.regplot(x = mean_runs, y = mean_opt_efficiency, color = 'k', label = 'Mean Optical Efficiency during one observation')#, x_bins=75\n",
    "#plt.errorbar(mean_runs, mean_opt_efficiency, yerr=std_opt, fmt = 'none', capsize=5, zorder=1, color='C0', alpha = 0.4)\n",
    "plt.grid(alpha = 0.3)\n",
    "plt.title(\"Optical Efficiency for all LST1 observational time\")\n",
    "#plt.vlines(3000,0,0.3)\n",
    "plt.ylim(0.1,0.275)\n",
    "plt.fill_betweenx(y=[0,0.3], x1 = 0, x2=x_fill[1], alpha = 0.05)\n",
    "plt.fill_betweenx(y=[0,0.3], x1 = x_fill[1], x2=x_fill[2], alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,0.3], x1 = x_fill[2], x2=x_fill[3], alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,0.3], x1 = x_fill[3], x2=x_fill[4], alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,0.3], x1 = x_fill[4], x2=x_fill[5], alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,0.3], x1 = x_fill[5], x2=18000, alpha = 0.075)\n",
    "plt.xlim(0,18000)\n",
    "plt.xlabel('Run number')\n",
    "plt.ylabel('Mean optical efficiency')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,9))\n",
    "sns.regplot(x = mean_runs, y = mean_size, color = 'k', label = 'Mean Intensity in the ring per one observation', x_bins=100)\n",
    "#plt.errorbar(mean_runs, mean_opt_efficiency, yerr=std_opt, fmt = 'none', capsize=5, zorder=1, color='C0', alpha = 0.4)\n",
    "plt.grid(alpha = 0.3)\n",
    "plt.title(\"Muon ring size (integral intensity in p.e.) for all LST1 observational time\")\n",
    "\n",
    "\n",
    "plt.fill_betweenx(y=[0,10000], x1 = 0, x2=x_fill[1], alpha = 0.05)\n",
    "plt.fill_betweenx(y=[0,10000], x1 = x_fill[1], x2=x_fill[2], alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,10000], x1 = x_fill[2], x2=x_fill[3], alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,10000], x1 = x_fill[3], x2=x_fill[4], alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,10000], x1 = x_fill[4], x2=x_fill[5], alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,10000], x1 = x_fill[5], x2=18000, alpha = 0.075)\n",
    "plt.xlim(0,18000)\n",
    "plt.ylim(1000,3000)\n",
    "plt.xlabel('Run number')\n",
    "plt.ylabel('Mean muon ring intensity per observation [p.e.]')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,9))\n",
    "sns.regplot(x = mean_runs, y = mean_width, color = 'k', label = 'Mean ring width per one observation', x_bins=75)\n",
    "#plt.errorbar(mean_runs, mean_opt_efficiency, yerr=std_opt, fmt = 'none', capsize=5, zorder=1, color='C0', alpha = 0.4)\n",
    "plt.grid(alpha = 0.3)\n",
    "plt.title(\"Muon ring width for all LST1 observational time\")\n",
    "\n",
    "\n",
    "plt.fill_betweenx(y=[0,10000], x1 = 1000, x2=x_fill[1], alpha = 0.05)\n",
    "plt.fill_betweenx(y=[0,10000], x1 = x_fill[1], x2=x_fill[2], alpha = 0.05)\n",
    "plt.fill_betweenx(y=[0,10000], x1 = x_fill[2], x2=x_fill[3], alpha = 0.05)\n",
    "plt.fill_betweenx(y=[0,10000], x1 = x_fill[3], x2=x_fill[4], alpha = 0.05)\n",
    "plt.fill_betweenx(y=[0,10000], x1 = x_fill[4], x2=x_fill[5], alpha = 0.05)\n",
    "plt.fill_betweenx(y=[0,10000], x1 = x_fill[5], x2=17000, alpha = 0.05)\n",
    "plt.xlim(0,18000)\n",
    "plt.ylim(0.01,0.3)\n",
    "plt.xlabel('Run number')\n",
    "plt.ylabel('Mean muon ring width per observation [deg]')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,9))\n",
    "sns.regplot(x = mean_runs, y = mean_radius, color = 'k', label = 'Mean muon ring radius per one observation', x_bins=75)\n",
    "#plt.errorbar(mean_runs, mean_opt_efficiency, yerr=std_opt, fmt = 'none', capsize=5, zorder=1, color='C0', alpha = 0.4)\n",
    "plt.grid(alpha = 0.3)\n",
    "plt.title(\"Muon ring radius for all LST1 observational time\")\n",
    "\n",
    "\n",
    "plt.fill_betweenx(y=[0,10000], x1 = 0, x2=x_fill[1], alpha = 0.05)\n",
    "plt.fill_betweenx(y=[0,10000], x1 = x_fill[1], x2=x_fill[2], alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,10000], x1 = x_fill[2], x2=x_fill[3], alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,10000], x1 = x_fill[3], x2=x_fill[4], alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,10000], x1 = x_fill[4], x2=x_fill[5], alpha = 0.075)\n",
    "plt.fill_betweenx(y=[0,10000], x1 = x_fill[5], x2=18000, alpha = 0.075)\n",
    "plt.xlim(0,18000)\n",
    "plt.ylim(0.9,1.3)\n",
    "plt.xlabel('Run number')\n",
    "plt.ylabel('Mean muon ring radius per observation [deg]')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.regplot(x = mean_radius, y = mean_size, color = 'k', label = 'Mean Optical Efficiency during one observation')\n",
    "plt.scatter(mean_radius,mean_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.regplot(x = cosmics_pd['mu_radius_mean'][(cosmics_pd['mu_radius_mean'] > 0.95) & (cosmics_pd['mu_radius_mean'] < 1.3)], y = cosmics_pd['mu_width_mean'][(cosmics_pd['mu_radius_mean'] > 0.95) & (cosmics_pd['mu_radius_mean'] < 1.3)], color = 'k', label = 'Mean Optical Efficiency during one observation')\n",
    "x = cosmics_pd['mu_radius_mean'][(cosmics_pd['mu_width_mean'] > 0.04) & (cosmics_pd['mu_width_mean'] < 0.3) & (cosmics_pd['mu_radius_mean'] > 0.95) & (cosmics_pd['mu_radius_mean'] < 1.3)]\n",
    "y = cosmics_pd['mu_width_mean'][(cosmics_pd['mu_width_mean'] > 0.04) & (cosmics_pd['mu_width_mean'] < 0.3) & (cosmics_pd['mu_radius_mean'] > 0.95) & (cosmics_pd['mu_radius_mean'] < 1.3)]\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cosmics_pd['mu_radius_mean'][(cosmics_pd['mu_radius_mean'] > 0.95) & (cosmics_pd['mu_radius_mean'] < 1.3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,9))\n",
    "plt.errorbar(x = mean_runs, y = mean_opt_efficiency, yerr = std_opt, fmt = 'x')#, color = 'k', label = 'Real Data')\n",
    "plt.grid(alpha = 0.5)\n",
    "plt.fill_betweenx(y=[0,0.65], x1 = x_fill[0], x2=x_fill[1], alpha = 0.1)\n",
    "plt.fill_betweenx(y=[0,0.65], x1 = x_fill[1], x2=x_fill[2], alpha = 0.1)\n",
    "plt.fill_betweenx(y=[0,0.65], x1 = x_fill[2], x2=x_fill[3], alpha = 0.1)\n",
    "plt.fill_betweenx(y=[0,0.65], x1 = x_fill[3], x2=x_fill[4], alpha = 0.1)\n",
    "plt.fill_betweenx(y=[0,0.65], x1 = x_fill[4], x2=x_fill[5], alpha = 0.1)\n",
    "plt.fill_betweenx(y=[0,0.65], x1 = x_fill[5], x2=x_fill[6], alpha = 0.1)\n",
    "plt.ylim(0.05,0.65)\n",
    "plt.title(\"Optical Efficiency\")\n",
    "plt.xlabel('Run number')\n",
    "plt.ylabel('Mean optical efficiency for observation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sc.stats.linregress(mean_runs,mean_opt_efficiency)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius2973 = []\n",
    "intensity2973 = []\n",
    "\n",
    "for observ in runsummary:\n",
    "    for i,run in enumerate(observ['runnumber']):\n",
    "        if run == 2973:\n",
    "            print(datetime.utcfromtimestamp(observ['time'][i]).strftime('%Y-%m-%d %H:%M:%S'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"2019 year = {dates.count(2019)}\")\n",
    "print(f\"2020 year = {dates.count(2020)}\")\n",
    "print(f\"2021 year = {dates.count(2021)}\")\n",
    "print(f\"2022 year = {dates.count(2022)}\")\n",
    "print(f\"2023 year = {dates.count(2023)}\")\n",
    "print(f\"2024 year = {dates.count(2024)}\")\n",
    "runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "runsummary[-1]['runnumber'][0] - runsummary[0]['runnumber'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(observation_date, mean_opt_efficiency)\n",
    "\n",
    "# format your data to desired format. Here I chose YYYY-MM-DD but you can set it to whatever you want.\n",
    "import matplotlib.dates as mdates\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%YYYY-%mm-%dd'))\n",
    "\n",
    "# rotate and align the tick labels so they look better\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x = cosmics_pd['runnumber'], y = cosmics_pd['num_contained_mu_rings'], color = 'k', label = 'Mean muon ring radius per one observation', x_bins=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmics_pd['runnumber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runsummary_pd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(runsummary_pd['ff_time_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_hdf(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(file) as hdf:\n",
    "    # This prints a list of all group names:\n",
    "    print(hdf.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cis.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(cis['diffuse_nsb_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cta-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
