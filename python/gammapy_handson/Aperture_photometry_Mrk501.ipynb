{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "We want to have access to the Science Data Challenge data, that are stored on dCache storage that is accessible from our JupyterHub with 'ctadata' service\n",
    "\n",
    "[<img src=\"platform.png\" width=\"250\"/>](image.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctadata\n",
    "ctadata.list_dir('cta/sdc-internal-data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "The metadata of all DL3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "ctadata.fetch_and_save_file('cta/sdc-internal-data/obs-index.fits.gz')\n",
    "hdul=fits.open('obs-index.fits.gz')\n",
    "pointings=hdul[1].data\n",
    "RA_pnts=pointings['RA_PNT']\n",
    "DEC_pnts=pointings['DEC_PNT']\n",
    "c_pnts=SkyCoord(RA_pnts,DEC_pnts,unit='degree')\n",
    "\n",
    "DL3_files=pointings['EVENTS_FILENAME']\n",
    "OBSIDs=pointings['OBS_ID']\n",
    "Tstart_sec=pointings['TSTART']\n",
    "Tstop_sec=pointings['TSTOP']\n",
    "OBJECT=pointings['OBJECT']\n",
    "date=pointings['DATE-OBS']\n",
    "time=pointings['TIME-OBS']\n",
    "Tstart=Time(date+'T'+time, format='isot', scale='utc').mjd \n",
    "date=pointings['DATE-END']\n",
    "time=pointings['TIME-END']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    ".... and metadata on instrument response functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctadata.fetch_and_save_file('cta/sdc-internal-data/hdu-index.fits.gz')\n",
    "hdul=fits.open('hdu-index.fits.gz')\n",
    "IRFS=hdul[1].data\n",
    "IRF_OBSID=IRFS['OBS_ID']\n",
    "IRF_FILE_NAME=IRFS['FILE_NAME']\n",
    "IRF_HDU_NAME=IRFS['HDU_NAME']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "We are interested in a specific source (say, Mrk 501). We do a \"simple cone search\" to find CTAO pointings that have the source within 3 degrees from the pointing direction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_s = SkyCoord.from_name('Mrk 501')\n",
    "RA_s=c_s.icrs.ra.deg\n",
    "DEC_s=c_s.icrs.dec.deg\n",
    "seps=c_s.separation(c_pnts).deg\n",
    "mask=(seps<3.)\n",
    "DL3_flist=DL3_files[mask]\n",
    "OBSIDlist=OBSIDs[mask]\n",
    "seps=seps[mask]\n",
    "RA_pnts=RA_pnts[mask]\n",
    "DEC_pnts=DEC_pnts[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Just in case, we create a copy of the directory tree with SDC data locally:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(DL3_flist[0])\n",
    "dir='products_SDC/Events/North'\n",
    "os.makedirs(dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in DL3_flist:\n",
    "    ctadata.fetch_and_save_file('cta/sdc-internal-data/'+f)\n",
    "    f=f.split('/')[-1]\n",
    "    !mv {f} {dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "The easiest thing to do is to create a \"countmap mosaic\" of all selected pointings in certain energy range, say above an energy threshold $E_{thr}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import cos,pi\n",
    "import numpy as np\n",
    "\n",
    "E_thr=0.1\n",
    "\n",
    "cdec=cos(DEC_s*pi/180.)\n",
    "imsize=5.\n",
    "pixsize=0.02\n",
    "npix=int(2*imsize/pixsize+1)\n",
    "ra_bins=np.linspace(RA_s-imsize/cdec,RA_s+imsize/cdec,npix+1)\n",
    "dec_bins=np.linspace(DEC_s-imsize,DEC_s+imsize,npix+1)\n",
    "mosaic=np.zeros((npix,npix))\n",
    "\n",
    "for f in DL3_flist:\n",
    "    hdul=fits.open(f)\n",
    "    ev=hdul['EVENTS'].data\n",
    "    ev_ra=ev['RA']\n",
    "    ev_dec=ev['DEC']\n",
    "    ev_en=ev['ENERGY']\n",
    "    mask=ev_en>E_thr\n",
    "    h=np.histogram2d(ev_ra[mask],ev_dec[mask],bins=[ra_bins,dec_bins])\n",
    "    mosaic+=h[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Just, in case, the convention in astronomy to show Right Ascension (RA) increasing from right to left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(np.flip(np.transpose(mosaic)),extent=(ra_bins[-1]+pixsize/cdec/2.,ra_bins[0]-pixsize/cdec/2.,dec_bins[0]-pixsize/2.,dec_bins[-1]+pixsize/2.),aspect=1/cdec)\n",
    "plt.colorbar(label='Counts per pixel')\n",
    "plt.xlabel('RA, degree')\n",
    "plt.ylabel('DEC, degree')\n",
    "plt.scatter([RA_s],[DEC_s],marker='x',color='white')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "For the spectral extraction, we want to calculate excess over the background, using the telescope \"wobbling\":\n",
    "[<img src=\"wobble.png\" width=\"250\"/>](wobble.png)\n",
    "\n",
    "We will collect events within certain \"aperture\" of the radius $R_s$ around the source position and estimate the background from the same aperture in the opposite wobble positions with respect to the center of the camera.\n",
    "\n",
    "We bin these events in logarithmic bins of reconstructed energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import log10,sqrt\n",
    "\n",
    "Emin=0.01    \n",
    "Emax=100. \n",
    "NEbins=20\n",
    "\n",
    "Erec_bins=np.logspace(log10(Emin),log10(Emax),NEbins+1)\n",
    "Erec_min=Erec_bins[:-1]\n",
    "Erec_max=Erec_bins[1:]\n",
    "Erec_mean=sqrt(Erec_min*Erec_max)\n",
    "lgErec_mean=log10(Erec_mean)\n",
    "dErec=Erec_bins[1:]-Erec_bins[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_s=0.3\n",
    "N_bkg=3\n",
    "\n",
    "Cts_s=[]\n",
    "Cts_b=[]\n",
    "N_b=[]\n",
    "\n",
    "for ind in range(len(DL3_flist)):\n",
    "    pointing=DL3_flist[ind]\n",
    "    hdul=fits.open(pointing)\n",
    "    ev=hdul['EVENTS'].data\n",
    "    ev_ra=ev['RA']\n",
    "    ev_dec=ev['DEC']\n",
    "    ev_en=ev['ENERGY']\n",
    "    ev_coords=SkyCoord(ev_ra,ev_dec,unit='degree')\n",
    "    sep_s=ev_coords.separation(c_s).deg\n",
    "    mask=(sep_s<R_s)\n",
    "    Cts_s.append(np.histogram(ev_en[mask],bins=Erec_bins)[0])\n",
    "    tmp=0.*Cts_s[-1]\n",
    "\n",
    "    dRA=RA_s-RA_pnts[ind]\n",
    "    dDEC=DEC_s-DEC_pnts[ind]\n",
    "    RA_b1=RA_pnts[ind]-dRA\n",
    "    DEC_b1=DEC_pnts[ind]-dDEC\n",
    "    c_b1=SkyCoord(RA_b1,DEC_b1,unit='degree')    \n",
    "    sep_b1=ev_coords.separation(c_b1).deg\n",
    "    mask=(sep_b1<R_s)\n",
    "    tmp+=np.histogram(ev_en[mask],bins=Erec_bins)[0]\n",
    "    RA_b2=RA_pnts[ind]-dDEC/cdec\n",
    "    DEC_b2=DEC_pnts[ind]+dRA*cdec\n",
    "    c_b2=SkyCoord(RA_b2,DEC_b2,unit='degree')    \n",
    "    sep_b2=ev_coords.separation(c_b2).deg\n",
    "    mask=(sep_b2<R_s)\n",
    "    tmp+=np.histogram(ev_en[mask],bins=Erec_bins)[0]\n",
    "    RA_b3=RA_pnts[ind]+dDEC/cdec\n",
    "    DEC_b3=DEC_pnts[ind]-dRA*cdec\n",
    "    c_b3=SkyCoord(RA_b3,DEC_b3,unit='degree')    \n",
    "    sep_b3=ev_coords.separation(c_b3).deg\n",
    "    mask=(sep_b3<R_s)\n",
    "    tmp+=np.histogram(ev_en[mask],bins=Erec_bins)[0]\n",
    "    Cts_b.append(tmp)\n",
    "\n",
    "\n",
    "    Texp=hdul[1].header['LIVETIME']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "This is the excess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "Src=sum(Cts_s)-sum(Cts_b)/N_bkg\n",
    "Src_err=sqrt(sum(Cts_s)+sum(Cts_b)/N_bkg**2)\n",
    "plt.plot(Erec_mean,sum(Cts_s),label='signal region')\n",
    "plt.plot(Erec_mean,sum(Cts_b)/N_bkg,label='background regions')\n",
    "plt.errorbar(Erec_mean,Src,Src_err,label='excess',xerr=[Erec_mean-Erec_min,Erec_max-Erec_mean],linestyle='none')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('$E_{rec}$, TeV')\n",
    "plt.ylabel('Counts')\n",
    "plt.legend(loc='lower left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "To convert the excess count statistics into flux measurements we need to know the exposure, product of exposure time $T_{exp}$ on effective area $A_{eff}$. \n",
    "$A_{eff}$, known from MC simulations, is estimated as a function of \"true\" energy of MC events. However, we know only \"reconstructed\" energy of real events. We need a mapping between the \"true\" and \"reconstructed\" energy. This mapping is called \"RMF\" (redistribution matrix function\"), or, otherwise, \"energy dispersion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEbins_true=150\n",
    "Et_min=0.01\n",
    "Et_max=100\n",
    "\n",
    "Etrue_bins=np.logspace(log10(Et_min),log10(Et_max),NEbins_true+1)\n",
    "Etrue_min=Etrue_bins[:-1]\n",
    "Etrue_max=Etrue_bins[1:]\n",
    "Etrue_mean=sqrt(Etrue_min*Etrue_max)\n",
    "lgEtrue_mean=log10(Etrue_mean)\n",
    "dEtrue=Etrue_bins[1:]-Etrue_bins[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=1\n",
    "resp_files='IRFS/fits/'+IRF_FILE_NAME[IRF_OBSID==OBSIDlist[ind]]\n",
    "j=0\n",
    "while(resp_files[j][10]!='P'):\n",
    "    j+=1\n",
    "resp_file=resp_files[j]\n",
    "hdul=fits.open(resp_file)\n",
    "RMF=hdul['ENERGY DISPERSION'].data\n",
    "ENERG_LO=RMF['ENERG_LO'][0]\n",
    "ENERG_HI=RMF['ENERG_HI'][0]\n",
    "ENERG=sqrt(ENERG_LO*ENERG_HI)\n",
    "MIGRA_LO=RMF['ENERG_LO'][0]\n",
    "MIGRA_HI=RMF['ENERG_HI'][0]\n",
    "MIGRA=(MIGRA_LO+MIGRA_HI)/2.\n",
    "mask=RMF['THETA_LO'][0]<seps[ind]\n",
    "ind_th=len(RMF['THETA_LO'][0][mask])-1\n",
    "RMF_th=RMF['MATRIX'][0][ind_th]\n",
    "\n",
    "#RMF_Erec=np.zeros((len(ENERG),len(Emeans)))\n",
    "pdf_tmp=np.zeros((len(ENERG),NEbins))\n",
    "for k in range(len(ENERG)):\n",
    "    #print(ENERG[k])\n",
    "    E=MIGRA*ENERG[k]\n",
    "    dE=E[1:]-E[:-1]\n",
    "    E=sqrt(E[1:]*E[:-1])\n",
    "    dpdf_dE=sqrt(RMF_th[1:,k]*RMF_th[:-1,k])/dE # this is differential PDF to have count in bin E (reconstructed) for true energy ENERG[k] \n",
    "    pdf_tmp[k]=np.interp(Erec_mean,E,dpdf_dE)*dErec\n",
    "pdf=np.zeros((NEbins_true,NEbins))\n",
    "for k in range(NEbins):\n",
    "    pdf[:,k]=np.interp(Etrue_mean,ENERG,pdf_tmp[:,k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMF['THETA_LO'],RMF['THETA_HI'],seps[ind],ind_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "seps[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "The 2d Gaussian with normalisation SCALE perhaps looks like this\n",
    "$$\n",
    "PSF(\\theta)=SCALE\\cdot \\exp\\left(-\\frac{\\theta^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "The integral is \n",
    "$$\n",
    "2\\pi\\int PSF(\\theta) \\theta d\\theta=2\\pi SCALE\\sigma^2\\int  \\exp\\left(-\\frac{\\theta^2}{2\\sigma^2}\\right) d\\left(\\frac{\\theta^2}{2\\sigma^2}\\right)=2\\pi\\sigma^2 SCALE\n",
    "$$\n",
    "If we are considering only counts within certain radius, the \"containment factor\" is\n",
    "$$\n",
    "CF=2\\pi SCALE\\sigma^2\\int_0^{R_s^2/2\\sigma^2}  \\exp\\left(-\\frac{\\theta^2}{2\\sigma^2}\\right) d\\left(\\frac{\\theta^2}{2\\sigma^2}\\right)=2\\pi\\sigma^2 SCALE\\left(1-\\exp\\left(-\\frac{R_s^2}{2\\sigma^2}\\right)\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "psf=hdul['POINT SPREAD FUNCTION'].data\n",
    "ENERG_LO=psf['ENERG_LO'][0]\n",
    "ENERG_HI=psf['ENERG_HI'][0]\n",
    "ENERG=sqrt(ENERG_LO*ENERG_HI)\n",
    "mask=psf['THETA_LO'][0]<seps[ind]\n",
    "ind_th=len(psf['THETA_LO'][0][mask])-1\n",
    "print(ind_th)\n",
    "#psf['SCALE']\n",
    "#psf['SIGMA_1']\n",
    "#psf['SIGMA_2']\n",
    "#psf['AMPL_2']\n",
    "#psf['AMPL_3']\n",
    "psf_scale=psf['SCALE'][0][ind_th]\n",
    "psf_sigma=psf['SIGMA_1'][0][ind_th]\n",
    "psf_CF=2*pi*psf_sigma*psf_scale*(1-exp(-R_s**2/2/psf_sigma**2))\n",
    "plt.plot(ENERG,psf_scale)\n",
    "plt.plot(ENERG,psf_sigma)\n",
    "plt.plot(ENERG,psf_CF)\n",
    "plt.plot(ENERG,psf['SIGMA_2'][0][ind_th])\n",
    "plt.plot(ENERG,psf['SIGMA_3'][0][ind_th])\n",
    "plt.plot(ENERG,psf['AMPL_2'][0][ind_th])\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "print(psf.columns)\n",
    "print(R_s)\n",
    "#PSF looks like single 2d Gaussian of the width SIGMA_1, with normalisation given by SCALE. \n",
    "#The other two Gaussians seem to have zero width and amplitude....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.shape\n",
    "i=110\n",
    "plt.step(Erec_bins,np.concatenate(([pdf[i,0]],pdf[i])))\n",
    "plt.xscale('log')\n",
    "plt.xlabel('$E_{rec}$, TeV')\n",
    "plt.ylabel('probability to find $E_{rec}$ between $E_{rec}$ and $E_{rec}+\\Delta E_{rec}$')\n",
    "plt.text(1e-2,0.6,r'$E_{true}=$'+str(Etrue_mean[i])+' TeV')\n",
    "plt.axvline(Etrue_mean[i],color='black',linestyle='dashed')\n",
    "sum(pdf[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.shape\n",
    "i=25\n",
    "plt.step(Erec_bins,np.concatenate(([pdf[i,0]],pdf[i])))\n",
    "plt.xscale('log')\n",
    "plt.xlabel('$E_{rec}$, TeV')\n",
    "plt.ylabel('probability to find $E_{rec}$ between $E_{rec}$ and $E_{rec}+\\Delta E_{rec}$')\n",
    "plt.text(1e-2,0.14,r'$E_{true}=$'+str(Etrue_mean[i])+' TeV')\n",
    "plt.axvline(Etrue_mean[i],color='black',linestyle='dashed')\n",
    "sum(pdf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.shape\n",
    "i=37\n",
    "plt.step(Erec_bins,np.concatenate(([pdf[i,0]],pdf[i])))\n",
    "plt.xscale('log')\n",
    "plt.xlabel('$E_{rec}$, TeV')\n",
    "plt.ylabel('probability to find $E_{rec}$ between $E_{rec}$ and $E_{rec}+\\Delta E_{rec}$')\n",
    "plt.text(1e-2,0.14,r'$E_{true}=$'+str(Etrue_mean[i])+' TeV')\n",
    "plt.axvline(Etrue_mean[i],color='black',linestyle='dashed')\n",
    "sum(pdf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMFs=[]\n",
    "Exposures=[]\n",
    "Responses=[]\n",
    "PSF_CFs=[]\n",
    "for ind in range(len(DL3_flist)):\n",
    "    resp_files='IRFS/fits/'+IRF_FILE_NAME[IRF_OBSID==OBSIDlist[ind]]\n",
    "    j=0\n",
    "    while(resp_files[j][10]!='P'):\n",
    "        j+=1\n",
    "    resp_file=resp_files[j]\n",
    "    hdul=fits.open(resp_file)\n",
    "    RMF=hdul['ENERGY DISPERSION'].data\n",
    "    ENERG_LO=RMF['ENERG_LO'][0]\n",
    "    ENERG_HI=RMF['ENERG_HI'][0]\n",
    "    ENERG=sqrt(ENERG_LO*ENERG_HI)\n",
    "    MIGRA_LO=RMF['ENERG_LO'][0]\n",
    "    MIGRA_HI=RMF['ENERG_HI'][0]\n",
    "    MIGRA=(MIGRA_LO+MIGRA_HI)/2.\n",
    "    mask=RMF['THETA_LO'][0]<seps[ind]\n",
    "    ind_th=len(RMF['THETA_LO'][0][mask])-1\n",
    "    RMF_th=RMF['MATRIX'][0][ind_th]\n",
    "    \n",
    "    #RMF_Erec=np.zeros((len(ENERG),len(Emeans)))\n",
    "    pdf_tmp=np.zeros((len(ENERG),NEbins))\n",
    "    for k in range(len(ENERG)):\n",
    "        #print(ENERG[k])\n",
    "        E=MIGRA*ENERG[k]\n",
    "        dE=E[1:]-E[:-1]\n",
    "        E=sqrt(E[1:]*E[:-1])\n",
    "        dpdf_dE=sqrt(RMF_th[1:,k]*RMF_th[:-1,k])/dE # this is differential PDF to have count in bin E (reconstructed) for true energy ENERG[k] \n",
    "        pdf_tmp[k]=np.interp(Erec_mean,E,dpdf_dE)*dErec\n",
    "    pdf=np.zeros((NEbins_true,NEbins))\n",
    "    for k in range(NEbins):\n",
    "        pdf[:,k]=np.interp(Etrue_mean,ENERG,pdf_tmp[:,k])\n",
    "    RMFs.append(pdf)\n",
    "    \n",
    "    AEFF=hdul['EFFECTIVE AREA'].data\n",
    "    ENERG_A_LO=AEFF['ENERG_LO'][0]\n",
    "    ENERG_A_HI=AEFF['ENERG_HI'][0]\n",
    "    ENERG_A=sqrt(ENERG_A_LO*ENERG_A_HI)\n",
    "    Effarea=AEFF['EFFAREA'][0][ind_th]\n",
    "    AT=np.interp(Etrue_mean,ENERG_A,Effarea)*Texp*1e4\n",
    "\n",
    "\n",
    "    psf=hdul['POINT SPREAD FUNCTION'].data\n",
    "    ENERG_LO=psf['ENERG_LO'][0]\n",
    "    ENERG_HI=psf['ENERG_HI'][0]\n",
    "    ENERG=sqrt(ENERG_LO*ENERG_HI)\n",
    "    mask=psf['THETA_LO'][0]<seps[ind]\n",
    "    ind_th=len(psf['THETA_LO'][0][mask])-1\n",
    "    psf_scale=psf['SCALE'][0][ind_th]\n",
    "    psf_sigma=psf['SIGMA_1'][0][ind_th]\n",
    "    psf_CF=2*pi*psf_sigma*psf_scale*(1-exp(-R_s**2/2/psf_sigma**2))\n",
    "    tmp=np.interp(Etrue_mean,ENERG,psf_CF)\n",
    "    Exposures.append(AT*tmp)\n",
    "    response=np.outer(Exposures[0],np.ones(NEbins))*RMFs[0]\n",
    "    Responses.append(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Etrue_mean,sum(Exposures))\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('$E_{true}$, TeV')\n",
    "plt.ylabel('$A_{eff}T_{exp}$, $cm^2s$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log10(Et_min),log10(Et_max),log10(Emin),log10(Emax))\n",
    "plt.imshow(np.transpose(RMFs[-1]),extent=(log10(Et_min),log10(Et_max),log10(Emin),log10(Emax)),origin='lower')\n",
    "plt.colorbar(label='pdf')\n",
    "plt.xlabel('$log10(E_{true}/TeV)$')\n",
    "plt.ylabel('$log10(E_{rec}/TeV)$')\n",
    "x=np.linspace(-2,2)\n",
    "plt.plot(x,x,color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "Above $E_{true}\\sim 30$ GeV the RMF is diagonal, so the reconstructed energy is a good proxy for the true energy. in such situation, we can make a simple estimate of the flux in each true/reconstructed energy bin \n",
    "$$\n",
    "E^2\\frac{dN}{dE}=\\frac{Cts_{src} E_{min}E_{max}}{(E_{max}-E_{min})}\n",
    "$$\n",
    "The data is reasonably well described by a broken powerlaw model, up to the energy $E\\simeq 10$~TeV (in reality, absorption on EBL needs to be considered for better modelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import exp\n",
    "E0=1.\n",
    "def bknpl_dNdE(E,N,Gam1,Gam2,Ebr,alpha):\n",
    "    return N*(E/E0)**(-Gam1)/(1+(E/Ebr)**alpha)**((Gam2-Gam1)/alpha)\n",
    "def cutoffpl_dNdE(E,N,Gam,Ecut,alpha):\n",
    "    return N*(E/E0)**(-Gam)*exp(-(E/Ecut)**alpha)\n",
    "\n",
    "Resp=sum(Responses)\n",
    "Exposure=sum(Exposures)\n",
    "Exposure_rec=np.interp(Erec_mean,Etrue_mean,Exposure)\n",
    "factor=1/Exposure_rec/(Erec_max-Erec_min)*Erec_min*Erec_max\n",
    "flux_simple=Src*factor\n",
    "flux_simple_err=Src_err*factor\n",
    "plt.errorbar(Erec_mean,flux_simple,flux_simple_err)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "\n",
    "Norm=1.27e-11\n",
    "Gam=2.13\n",
    "Ecut=1/2.1370e-01\t\n",
    "alpha=1\n",
    "y=cutoffpl_dNdE(Erec_mean,Norm,Gam,Ecut,alpha)\n",
    "plt.plot(Erec_mean,y*Erec_mean**2)\n",
    "plt.ylim(1e-13,1e-10)\n",
    "plt.axvline(10**(-1.5),color='black',linestyle='dashed')\n",
    "plt.xlabel('$E$, TeV')\n",
    "plt.ylabel('$E^2 dN/dE$, TeV/cm$^2$s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "Efit_min=10**(-1.5)\n",
    "Efit_max=10.\n",
    "def cutoffpl_counts(p):\n",
    "    N,Gam,Ecut,alpha = p\n",
    "    model=cutoffpl_dNdE(Etrue_mean,N,Gam,Ecut,alpha)*(Etrue_max-Etrue_min)\n",
    "    return np.matmul(model,Resp)\n",
    "\n",
    "Norm=1.27e-11\n",
    "Gam=2.13\n",
    "Ecut=1/2.1370e-01\t\n",
    "alpha=1\n",
    "m=cutoffpl_counts([Norm,Gam,Ecut,alpha])\n",
    "plt.plot(Erec_mean,m)\n",
    "plt.errorbar(Erec_mean,Src,Src_err)\n",
    "plt.axvline(Efit_min,color='black',linestyle='dashed')\n",
    "plt.axvline(Efit_max,color='black',linestyle='dashed')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylim(0.1,1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "Syst=0.05\n",
    "\n",
    "def chisq(p):\n",
    "    model=cutoffpl_counts(p)\n",
    "    return (((model - Src)/(sqrt(Src_err**2+(Syst*Src)**2)+1e-20))[mask]**2).sum()\n",
    "def chisq_log(p):\n",
    "    p=[10**p[0],p[1],10**p[2],1]\n",
    "    model=cutoffpl_counts(p)\n",
    "    return (((model - Src)/(sqrt(Src_err**2+(Syst*Src)**2)+1e-20))[mask]**2).sum()\n",
    "\n",
    "mask = Erec_mean > Efit_min\n",
    "mask &= Erec_mean < Efit_max\n",
    "mask &= Src_err>0.\n",
    "dof=sum(mask)\n",
    "print(dof)\n",
    "#1.e-11,1.5,3.5,0.3\n",
    "#Norm,Gam,Ecut,alpha\n",
    "f = minimize(chisq_log, (log10(Norm),Gam,log10(Ecut)),method='Powell')\n",
    "print(f)\n",
    "N_best=10**(f.x[0])\n",
    "Gam_best=f.x[1]\n",
    "Ecut_best=10**f.x[2]\n",
    "print(N_best,Gam_best,Ecut_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(Erec_mean,Src,Src_err)\n",
    "\n",
    "model_best=cutoffpl_counts([N_best,Gam_best,Ecut_best,alpha_best])\n",
    "plt.plot(Erec_mean,model_best)\n",
    "excess=(Src-model_best)/model_best\n",
    "excess_err=Src_err/model_best\n",
    "\n",
    "plt.axvline(Efit_min,color='black',linestyle='dashed')\n",
    "plt.axvline(Efit_max,color='black',linestyle='dashed')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylim(0.1,1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "m=cutoffpl_dNdE(Erec_mean,N_best,Gam_best,Ecut_best,1)\n",
    "plt.plot(Erec_mean,m*Erec_mean**2)\n",
    "plt.errorbar(Erec_mean,flux_simple,flux_simple_err)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.ylim(1e-13,1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
